---
title: "Oregon 2013 Medication for Beta-2 agonists"
author: "Jingyang Liu"
date: "May 17, 2017"
output: html_document
---

```{r library, include=FALSE, echo=FALSE}
library(tidyverse)
# library(data.table)
library(survival)
library(ggplot2)
library(htmlTable)
library(knitr)
library(broom)
library(lme4)
library(maps)
library(lubridate) # date

# distributed lag model libraries
library(dlnm)
library(mvmeta)
library(splines)

```


## Overview

We had previously shown GWR to be a good estimate of wildfire smoke concentrations, and showed associations with respiratory outcomes (including asthma) in Washington state. We want to replicate results for Oregon and also look at beta-2 agonist pharmacy fills.

For this research I have the Oregon All Payer All Claims (APAC) data set in 2013. I want to research on the effects of wildfire GWR smoke on beta-2 agonist pharmacy fill, a medication primarily used as a rescue medication for persons with asthma or COPD. NDC (National Drug Code) is the variable in the data set that the data set offered. The standard NDC I use the link below, which is a ndc list in 2013 and fits my original data set. 
(http://ww2.ncqa.org/hedis-quality-measurement/hedis-measures/hedis-2013/hedis-2013-final-ndc-lists)

The data cleaning and creation of the casecross-over dataframes are huge computation tasks, so they are done with server, the following work is done with local R. We analyze the case crossover results with overall, age strarified and sex stratified categories for the pharmacy fills, and then we also analyze with the distributed lag method, and check with time series analysis.


## Method Description

In these comparisons, we examine GWR method of smoke PM2.5 estimations and associations with health outcomes using a time-stratified case-crossover study design. Pharmacy outcomes for a patient with a primary diagnosis of all pharmacy records from the state, and it just so happens we also have APAC data for people that were billed for a cardiopulmonary event that we can link to the pharmacy claim, and their date of admission (index time) were identified. We then created counterfactual observations for each patient on the same day of the week for the entire wildfire season (May 1st to Sep 30th, 2013). For patients who have a index time before May 1, 2013 or after September 30, 2013, their referent observations before or after these dates will be excluded as I will not be able to assign estimates of PM2.5 to these referent observations.

1. Data cleaning for health outcomes

There are about 77 million claims in the total data set, of which 23 million are pharmacy records denoted by the NDC variable. So I choose the claims in Oregon State with ndc existing, which is about 23 million claims. Also, the POS (Place of service code) all show "pharmacy" type, comparing to the previous health disease outcomes we limit the "emergency visit" type or "urgent care" type.

For ndc, I choose the people the person was billed for filling a beta2 agonist prescription, which we use as a proxy for use to form the sample. Because the ndc csv file has more information than what I need, I filter the ndc file by SQLite Studio (code and steps not attached) to a file only containing the beta 2 agonists medication information. 

After choosing the claims with beta 2 agonists, the data set is reduced to 232,665 observations. After first recorded pharmacy fill and limit the wildfire season dates (May 1st, 2013 to September 30th, 2013), the data set is the final data set used for analysis and contained 24,538 beta2 agonist records.

```{r import filtered original data, eval=FALSE, echo=FALSE}
### Import whole data set ------------------------------------------------------
read_path <- paste0("../../../data/data_original/gan_episodes_of_care.txt")
start_time <- Sys.time()
oregon_df <- fread(read_path, sep = "|", showProgress = T) 
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 7 mins

### Import NDC data set --------------------------------------------------------
read_path <- paste0("../../../data/data_new/oregon_ndc.csv")
oregon_ndc <- read_csv(read_path)
dim(oregon_ndc) # 23330714 obs

## Import Asthma NDC table
read_path2 <- paste0("../../../data/data_new/ndc_2013_beta_2_agonists.csv")
inhaler_ndc <- read_csv(read_path2, col_names = FALSE)

colnames(inhaler_ndc) <- c("ndc_code", "brand_name", "generic_product_name", 
                          "route", "category", "drug_id")

# convert to vector
ndc_codes <- as.vector(as.matrix(inhaler_ndc$ndc_code))

oregon_beta <- oregon_ndc %>%
  filter(ndc %in% ndc_codes) # 232665, unique personkey 83787

oregon_beta_df <- oregon_beta %>% 
  group_by(personkey) %>% 
  arrange(personkey, fromdate, line) %>% 
  mutate(num_visit = dense_rank(fromdate)) %>%
  arrange(personkey, num_visit) %>% 
  select(personkey, clmid, num_visit) %>% 
  unique() %>% 
  full_join(oregon_beta, by = c("personkey", "clmid")) %>% 
  arrange(personkey, clmid, line, fromdate) %>% 
  filter(row_number() == 1) %>%
  # add new transverted from date
  mutate(dates = as.Date(fromdate, "%m/%d/%Y")) # 83787 (same)


oregon_df_ndc <- oregon_df %>%
  filter(personkey %in% oregon_beta$personkey) # 8909892

### Import ICD9 code
icd9_key <- read_excel("../../../data/data_original/CMS32_DESC_LONG_SHORT_DX.xlsx") %>% 
  # rename the terrible variable names
  select(dx_code = 1, long_desc = 2, short_desc = 3)

# sort by icd9 code add row variable 
icd9_key$X <- NULL
icd9_key <- arrange(icd9_key, dx_code) %>%
  mutate(n = as.numeric(row.names(icd9_key)))

### without ICD-9
or_ndc_no_icd <- oregon_df_ndc %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="" )

length(or_ndc_no_icd$personkey) # 3656720 claims
length(unique(or_ndc_no_icd$personkey)) # 83787



or_no_ndc_no_icd <- oregon_df %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 1057022 missing in total data set
         

or_ndc_all_miss <- oregon_df_ndc %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 20269 missing in total data set

or_ndc_all_miss_id <- or_ndc_asthma_df %>%
  filter(personkey %in% unique(or_ndc_copd_df$personkey)) %>% # 7279 person
  select(personkey)

oregon_ndc_dx <- oregon_ndc %>%
    filter(dx1!="*NULL*" |
         dx2!="*NULL*" |
         dx3!="*NULL*" |
         dx4!="*NULL*" |
         dx5!="*NULL*" |
         dx6!="*NULL*" |
         dx7!="*NULL*" |
         dx8!="*NULL*" |
         dx9!="*NULL*" |
         dx10!="*NULL*" |
         dx11!="" |
         dx12!="" |
         dx13!="" ) # 0 claims 


### asthma
which(icd9_key$dx_code == '49300') # start of asthma is row 5206
which(icd9_key$dx_code == '49392') # end of asthma is row 5219

# limit just to asthma code and just the diagnosis column
icd9_check <- icd9_key %>%
  filter(n >= 5206 & n <= 5219) 
icd9_check

asthma_icd9 <- filter(icd9_key, n >= 5206 & n <= 5219) %>%
  select(dx_code)
# convert to vector
asthma_icd9 <- as.vector(as.matrix(asthma_icd9))   

# now can I make a new variable, asthma1, that indicates an asthma claim?
or_ndc_asthma_df <- oregon_df_ndc %>%
  filter(dx1 %in% asthma_icd9 |
         dx2 %in% asthma_icd9 |
         dx3 %in% asthma_icd9 |
         dx4 %in% asthma_icd9 |
         dx5 %in% asthma_icd9 |
         dx6 %in% asthma_icd9 |
         dx7 %in% asthma_icd9 |
         dx8 %in% asthma_icd9 |
         dx9 %in% asthma_icd9 |
         dx10 %in% asthma_icd9 |
         dx11 %in% asthma_icd9 |
         dx12 %in% asthma_icd9 |
         dx13 %in% asthma_icd9) # 375451, unique personkey: 45165


### COPD
copd_icd9 <- c('490', '4910','4911','49120','49121','49122','4918','4919', '4920',
               '4928', '4940', '4941', '496') 

# now can I make a new variable, asthma1, that indicates an asthma claim?
or_ndc_copd_df <- oregon_df_ndc %>%
  filter(dx1 %in% copd_icd9 |
         dx2 %in% copd_icd9 |
         dx3 %in% copd_icd9 |
         dx4 %in% copd_icd9 |
         dx5 %in% copd_icd9 |
         dx6 %in% copd_icd9 |
         dx7 %in% copd_icd9 |
         dx8 %in% copd_icd9 |
         dx9 %in% copd_icd9 |
         dx10 %in% copd_icd9 |
         dx11 %in% copd_icd9 |
         dx12 %in% copd_icd9 |
         dx13 %in% copd_icd9) # 361738, unique personkey: 18626

### asthma or copd
or_or_asthma_copd <- oregon_df_ndc %>%
  filter(dx1 %in% asthma_icd9 |
         dx2 %in% asthma_icd9 |
         dx3 %in% asthma_icd9 |
         dx4 %in% asthma_icd9 |
         dx5 %in% asthma_icd9 |
         dx6 %in% asthma_icd9 |
         dx7 %in% asthma_icd9 |
         dx8 %in% asthma_icd9 |
         dx9 %in% asthma_icd9 |
         dx10 %in% asthma_icd9 |
         dx11 %in% asthma_icd9 |
         dx12 %in% asthma_icd9 |
         dx13 %in% asthma_icd9 |
         dx1 %in% copd_icd9 |
         dx2 %in% copd_icd9 |
         dx3 %in% copd_icd9 |
         dx4 %in% copd_icd9 |
         dx5 %in% copd_icd9 |
         dx6 %in% copd_icd9 |
         dx7 %in% copd_icd9 |
         dx8 %in% copd_icd9 |
         dx9 %in% copd_icd9 |
         dx10 %in% copd_icd9 |
         dx11 %in% copd_icd9 |
         dx12 %in% copd_icd9 | 
         dx13 %in% copd_icd9) # 722107 , unique personkey: 56512

# 45165+ 18626 - 56512
# [1] 7279 on both asthma and copd

### Both asthma and copd
length(unique(or_or_asthma_copd$personkey))
length(unique(or_ndc_asthma_df$personkey))
length(unique(or_ndc_copd_df$personkey))

or_with_icd <- oregon_df_ndc %>%
  filter(!dx1=="*NULL*" |
         !dx2=="*NULL*" |
         !dx3=="*NULL*" |
         !dx4=="*NULL*" |
         !dx5=="*NULL*" |
         !dx6=="*NULL*" |
         !dx7=="*NULL*" |
         !dx8=="*NULL*" |
         !dx9=="*NULL*" |
         !dx10=="*NULL*" |
         !dx11=="" |
         !dx12=="" |
         !dx13=="" )

asthma_copd_both_id <- or_ndc_asthma_df %>%
  filter(personkey %in% unique(or_ndc_copd_df$personkey)) %>% # 7279 person
  select(personkey) %>%
  unique() %>%
  mutate(index="both")
  
### Only asthma
asthma_only_id <- or_ndc_asthma_df %>%
  filter(!personkey %in% asthma_copd_both_id$personkey) %>% # 37886 person
  select(personkey) %>%
  unique() %>%
  mutate(index="asthma")


### Only copd
copd_only_id <- or_ndc_copd_df %>%
  filter(!personkey %in% asthma_copd_both_id$personkey) %>% # 11347 person
  select(personkey) %>%
  unique() %>%
  mutate(index="copd")


### Other
other_disease_id <- oregon_df_ndc %>%
  filter(!personkey %in% or_or_asthma_copd$personkey) %>% # 27275 person
  select(personkey) %>%
  unique() %>%
  mutate(index="other")

id_index <- bind_rows(asthma_copd_both_id, asthma_only_id, copd_only_id, other_disease_id)

## Join the index with beta 2 ndc claims
oregon_beta_index <- oregon_beta %>%
  left_join(id_index, by="personkey")
summary(as.factor(oregon_beta_index$index))

write_path3 <- paste0('../../../data/data_new/',
                     'oregon_beta_ndc_index.csv')
write_csv(oregon_beta_index, write_path3) 


## Join with original data and indicator for 4 categories
oregon_ndc_index <- oregon_df_ndc %>%
  left_join(id_index, by="personkey")
summary(as.factor(oregon_ndc_index$index))

### Check
or_ndc_asthma_copd_sum <- oregon_ndc_index %>%
  mutate(asthma1 = ifelse(dx1 %in% asthma_icd9, 1, 0),
         asthma2 = ifelse(dx2 %in% asthma_icd9, 1, 0),
         asthma3 = ifelse(dx3 %in% asthma_icd9, 1, 0),
         asthma4 = ifelse(dx4 %in% asthma_icd9, 1, 0),
         asthma5 = ifelse(dx5 %in% asthma_icd9, 1, 0),
         asthma6 = ifelse(dx6 %in% asthma_icd9, 1, 0),
         asthma7 = ifelse(dx7 %in% asthma_icd9, 1, 0),
         asthma8 = ifelse(dx8 %in% asthma_icd9, 1, 0),
         asthma9 = ifelse(dx9 %in% asthma_icd9, 1, 0),
         asthma10 = ifelse(dx10 %in% asthma_icd9, 1, 0),
         asthma11 = ifelse(dx11 %in% asthma_icd9, 1, 0),
         asthma12 = ifelse(dx12 %in% asthma_icd9, 1, 0),
         asthma13 = ifelse(dx13 %in% asthma_icd9, 1, 0),
         # sum up the asthma indicators
         asthma_sum = (asthma1 + asthma2 + asthma3 + asthma4 + asthma5 + asthma6 + asthma7 + asthma8 + asthma9 + asthma10 + asthma11 + asthma12 + asthma13),
         asthma_dx = ifelse(asthma_sum>0, asthma_sum, 0)
         ) %>% # end of mutate asthma
  mutate(copd1 = ifelse(dx1 %in% copd_icd9, 1, 0),
         copd2 = ifelse(dx2 %in% copd_icd9, 1, 0),
         copd3 = ifelse(dx3 %in% copd_icd9, 1, 0),
         copd4 = ifelse(dx4 %in% copd_icd9, 1, 0),
         copd5 = ifelse(dx5 %in% copd_icd9, 1, 0),
         copd6 = ifelse(dx6 %in% copd_icd9, 1, 0),
         copd7 = ifelse(dx7 %in% copd_icd9, 1, 0),
         copd8 = ifelse(dx8 %in% copd_icd9, 1, 0),
         copd9 = ifelse(dx9 %in% copd_icd9, 1, 0),
         copd10 = ifelse(dx10 %in% copd_icd9, 1, 0),
         copd11 = ifelse(dx11 %in% copd_icd9, 1, 0),
         copd12 = ifelse(dx12 %in% copd_icd9, 1, 0),
         copd13 = ifelse(dx13 %in% copd_icd9, 1, 0),
         # sum up the pneumonia indicators
         copd_sum = (copd1 + copd2 + copd3 + copd4 +copd5 + copd6 + copd7 + copd8 + copd9 +copd10 + copd11 + copd12 + copd13),
         copd_dx = ifelse(copd_sum>0, copd_sum, 0)
  ) #end of mutate of copd
  

or_ndc_check <- or_ndc_asthma_copd_sum %>%
  select(personkey, index, asthma_dx, copd_dx)
summary(as.factor(or_ndc_check$asthma_dx))

or_asthma <- or_ndc_asthma_copd_sum %>%
  filter(index=="asthma")
or_copd <- or_ndc_asthma_copd_sum %>%
  filter(index=="copd")
or_both <- or_ndc_asthma_copd_sum %>%
  filter(index=="both")
or_other <- or_ndc_asthma_copd_sum %>%
  filter(index=="other")

summary(as.factor(or_other$dx1))

## check for one sample
summary(as.factor(or_asthma$personkey))
summary(as.factor(or_copd$personkey))
summary(as.factor(or_both$personkey))
summary(as.factor(or_other$personkey))


or_asthma_sample <- or_asthma %>%
  filter(personkey == 10101244) 
which(or_asthma_sample$asthma_dx!=0)

or_copd_sample  <- or_copd %>%
  filter(personkey == 13564804) 

or_both_sample  <- or_both %>%
  filter(personkey == 12979399) 

or_other_sample  <- or_other %>%
  filter(personkey == 10289787) 


or_asthma_miss <- or_asthma %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 89482 claims missing in asthma data set

or_copd_miss <- or_copd %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 18941 claims missing in copd data set


or_both_miss <- or_both %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 17963 claims missing in both data set


or_other_miss <- or_other %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 46971 claims missing in other data set (5848 personkey)

or_other_not_miss <- or_other %>%
  filter(dx1!="*NULL*" |
         dx2!="*NULL*" |
         dx3!="*NULL*" |
         dx4!="*NULL*" |
         dx5!="*NULL*" |
         dx6!="*NULL*" |
         dx7!="*NULL*" |
         dx8!="*NULL*" |
         dx9!="*NULL*" |
         dx10!="*NULL*" |
         dx11!="" |
         dx12!="" |
         dx13!="" |
         ndc!="" |
         ndc!="*NULL*") # 20269 missing in total data set

length(unique(or_other_not_miss$personkey)) # [1] 27275

dim(or_asthma_miss)
dim(or_copd_miss)
dim(or_both_miss)
dim(or_other_miss)


sum(or_ndc_all_miss_id %in% unique(or_other$personkey))


write_path <- paste0('../../../data/data_new/',
                     'oregon_asthma_sample.csv')
write_csv(or_asthma_sample, write_path) 

write_path2 <- paste0('../../../data/data_new/',
                     'oregon_ndc_with_index.csv')

write_csv(or_ndc_asthma_copd_sum, write_path2)


```

```{r choose ndc, eval=FALSE, echo=FALSE}

# limit to the unique personkey different days' first visit
oregon_asthma_df <- oregon_asthma %>% 
  group_by(personkey) %>% 
  arrange(personkey, fromdate, line) %>% 
  mutate(num_visit = dense_rank(fromdate)) %>%
  arrange(personkey, num_visit) %>% 
  select(personkey, clmid, num_visit) %>% 
  unique() %>% 
  full_join(oregon_asthma, by = c("personkey", "clmid")) %>% 
  arrange(personkey, clmid, line, fromdate) %>% 
  filter(row_number() == 1) %>%
  # add new transverted from date
  mutate(dates = as.Date(fromdate, "%m/%d/%Y")) %>%
  filter(dates >= '2013-05-01' & 
         dates <= '2013-09-30') # 24538

write_path2 <- paste0("../../../data/data_new/oregon_asthma_ndc.csv")
write_csv(oregon_asthma_df, write_path2)

```

2. Exposure methods for smoke model

For our research question, we focus on the GWR method (geographically weighted ridge regression). For Geo-Weighted Regression model, with 'smk' designator, I subtracted off the 'Background' estimates of smoke, which I believe are the monthly averages of PM2.5 for a given grid. However, the 'Background' is the mean of total period from May 1st to Sep 30th 2013 so I have to assign the mean for every day. 

3. Analytic method

We use the conditional logistic regression model using the survival package in R. Each conditional logistic regression model accounts for the subject, and adjusts for temperature from the WRF-Chem model. The conditional logistic regression model \beta represents the change in risk of an pharmacy event associated with a short-term unit increase in exposure, and can be calculated as an average difference between exposure at the index time and a weighted average of exposure at all times in the referent window. 

```{r import original data, eval=FALSE, echo=FALSE}
### Import whole data set ------------------------------------------------------
read_path <- paste0("../../../data/data_original/gan_episodes_of_care.txt")
start_time <- Sys.time()
oregon_df <- fread(read_path, sep = "|", showProgress = T) 
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 7 mins

## Basic cleaning
start_time <- Sys.time()
oregon_df2 <- oregon_df %>% 
  filter((!ndc=="")&(!ndc=="*NULL*")) %>% 
  # filter State is Oregon
  filter(STATE=="OR")
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 40 secs

write_path <- paste0('../../../data/data_new/',
                     'oregon_ndc.csv')
write_csv(oregon_df2, write_path)
```


### Time-Stratified Case-Crossover (Population-Weighted PM~2.5~ Assigned by Zip Code)
*referents same day of week within fire season May - September*
 
The time-stratified casecross-over design uses subjects as their own controls. For each pharmacy claim, I also created counterfactual observations on the the same day of the week over the study period for each subject to indicate the outcome for this day is "1". Then I make the dates week by week before this date, and after this date in the whole wildfire season, and indicate these dates' outcomes are "0". Then I can use these outcomes for the following model building.

```{r casecrossover, eval=FALSE, echo=FALSE}
### Casecrossover study
read_path3 <- paste0("../../../data/data_new/medication/oregon_asthma_ndc.csv")
oregon_asthma_df <- read_csv(read_path3)


outcome_id <- oregon_asthma_df %>%
  # arrange with dates
  arrange(dates) %>%
  mutate(id = seq(1, nrow(.), by = 1))

# create dataset to populate
id_date_df <- data_frame()


# begin second loop to create counterfactual observations for each case subject
for (k in 1:nrow(outcome_id)){
  
  # find the replicate times of weeks
  dates_l <- outcome_id[[k,74]] 
  n1 <- 0
  d=as.Date("2013-05-01")
  i=1
  while (dates_l >= "2013-05-01"){
    dates_l <- dates_l - 7
    d[i] = dates_l
    i = i+1
    n1 = n1+1
  }
  d[1:n1-1] # shows character(0) when the first week
  n1-1
  
  dates_l <- outcome_id[[k,74]] 
  n2=0
  e=as.Date("2013-09-30")
  j=1
  while (dates_l <= "2013-09-30"){
    dates_l <- dates_l + 7
    e[j]=dates_l
    j=j+1
    n2 = n2 + 1
  }
  e[1:n2-1] # shows character(0) when the last week
  n2-1
  
  # replicate covariates length of counterfactual dates
  # and make conuterfactual dates
  if (n1==1){
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], e[1:n2-1])
  } else if (n2==1){
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], d[1:(n1-1)])
  }else{
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], d[1:(n1-1)], e[1:n2-1])
  }
  
  # bind unique id and date of the year with covariates
  id_date <- bind_cols(cov_df)
  # iteration which binds rows of unique ids
  id_date_df <- bind_rows(id_date_df, id_date)
}

outcome_casecross <- id_date_df %>%
  mutate(outcome = ifelse(dates == as.Date(fromdate, "%m/%d/%Y"), 1, 0)) %>%
  arrange(id, dates) # order by id and date

outcome_casecross <- id_date_df %>%
  mutate(outcome = ifelse(dates == as.Date(fromdate, "%m/%d/%Y"), 1, 0)) %>%
  arrange(personkey, dates) # order by id and date

write_path2 <- paste0("../../../data/data_new/oregon_ndc_casecrossover.csv")
write_csv(outcome_casecross, write_path2)

```

To get the time stratified data set, I create the lag variables that take smoke values from the previous days for zip codes, join the zipcode level populatoin-weighted pm to the data set, and create age, sex, month and season index.

```{r time stratified zip for casecrossover, eval=FALSE, echo=FALSE}
### Time stratified ------------------------------------------------------------
# read in zipcode level populatoin-weighted pm
read_path5 <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data/Oregon_PM/zip_pm_to_merge_with_acap.csv')

zip_smoke <- read_csv(read_path5) # 63801 rows

# descriptives of the two smoke datasets
summary(zip_smoke)

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
zip_smoke_w_lag <- zip_smoke %>% arrange(ZIPCODE, date) %>%
  # group by zipcode
  group_by(ZIPCODE) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_f_pm, 1, order_by = ZIPCODE), 
         wrf_f_pm_lag2 = lag(wrf_f_pm, 2, order_by = ZIPCODE),
         wrf_f_pm_lag3 = lag(wrf_f_pm, 3, order_by = ZIPCODE),
         wrf_f_pm_lag4 = lag(wrf_f_pm, 4, order_by = ZIPCODE),
         wrf_f_pm_lag5 = lag(wrf_f_pm, 5, order_by = ZIPCODE),
         wrf_f_pm_lag6 = lag(wrf_f_pm, 6, order_by = ZIPCODE),
         wrf_f_pm_lag7 = lag(wrf_f_pm, 7, order_by = ZIPCODE),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = ZIPCODE),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = ZIPCODE),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = ZIPCODE),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = ZIPCODE),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = ZIPCODE),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = ZIPCODE),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = ZIPCODE),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = ZIPCODE),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = ZIPCODE),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = ZIPCODE),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = ZIPCODE),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = ZIPCODE),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = ZIPCODE),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = ZIPCODE),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = ZIPCODE),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = ZIPCODE),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = ZIPCODE),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = ZIPCODE),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = ZIPCODE),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = ZIPCODE),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = ZIPCODE),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = ZIPCODE),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = ZIPCODE),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = ZIPCODE),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = ZIPCODE),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = ZIPCODE), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = ZIPCODE),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = ZIPCODE), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = ZIPCODE),
         background_pm_lag2 = lag(background_pm, 2, order_by = ZIPCODE),
         background_pm_lag3 = lag(background_pm, 3, order_by = ZIPCODE),
         background_pm_lag4 = lag(background_pm, 4, order_by = ZIPCODE),
         background_pm_lag5 = lag(background_pm, 5, order_by = ZIPCODE), 
         background_pm_lag6 = lag(background_pm, 6, order_by = ZIPCODE),
         background_pm_lag7 = lag(background_pm, 7, order_by = ZIPCODE), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = ZIPCODE),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = ZIPCODE),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = ZIPCODE),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = ZIPCODE),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = ZIPCODE),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = ZIPCODE),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = ZIPCODE),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = ZIPCODE),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = ZIPCODE),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = ZIPCODE),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = ZIPCODE),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = ZIPCODE),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = ZIPCODE),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = ZIPCODE),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = ZIPCODE),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = ZIPCODE),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = ZIPCODE),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = ZIPCODE),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = ZIPCODE), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = ZIPCODE),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = ZIPCODE)) %>% 
  # ungroup by zip
  ungroup(ZIPCODE) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "zip", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(ZIPCODE = ZIPCODE_zip, date = date_zip)

read_path4 <- paste0("../data_new/medication/oregon_ndc_casecrossover.csv")
# read_path4 <- paste0("../../../data/data_new/oregon_ndc_casecrossover.csv") # for server
or_disease <- read_csv(read_path4)

### try join
colnames(or_disease)[24] <- c("ZIPCODE")
colnames(or_disease)[74] <- c("date")

outcome_casecross <- or_disease %>%
  # indicator for male=0, female=1, unknown = 2
  mutate(age = 2013-yob,
         sex_ind =ifelse(gender == "F", 1, 
                         ifelse(gender == "M", 0, 2)),
         age_ind = ifelse(age < 15, 0,
                          ifelse(age >= 15 & age < 65, 1,
                                 ifelse(age >= 65 & age <=105, 2, NA)))
  ) %>% # end of mutate 
  # create variables
  mutate(day = as.factor(weekdays(fromdate)),
         day_admit = as.factor(weekdays(date)),
         month_smk = month(fromdate),
         month_admit = month(date),
         season_smk = ifelse(fromdate >= "2013-03-20" &  
                               fromdate <= "2013-06-21", "spring",
                             ifelse(fromdate >= "2013-06-22" &  
                                      fromdate <= "2013-09-22", "summer",
                                    ifelse(fromdate >= "2013-09-23" & 
                                             fromdate <= "2013-12-21", "fall", "other"))),
         season_admit = ifelse(date >= "2013-03-20" &  
                                 date <= "2013-06-21", "spring",
                               ifelse(date >= "2013-06-22" &  
                                        date <= "2013-09-22", "summer",
                                      ifelse(date >= "2013-09-23" & 
                                               date <= "2013-12-21", "fall", "other")))) %>%
  # join with zip-level pm estimates
  left_join(zip_smoke_w_lag, by = c("date", "ZIPCODE"))%>%
  arrange(personkey, fromdate) # order by id and fromdate

write_path4 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip.csv")
write_csv(outcome_casecross, write_path4)

```

### Time stratified for time series (Population-Weighted PM~2.5~ Assigned by County)

I also make time stratified time series data set. The original data set only contains the zip code, but for time series, we want to research on the county level. Therefore, I assign each zip code with one county which I found online. There are 488 zipcodes in total (4 are missing but I use google to find it). This is a sensitivity analysis to confirm the casecross over results.

```{r time stratified county for ts, echo=FALSE, include=FALSE, eval=FALSE}
read_path7 <- paste0("../data_new/medication/oregon_asthma_ndc.csv")
or_ndc_claim <- read_csv(read_path7)

or_ndc_inhaler <- or_ndc_claim %>%
  select(personkey, num_visit, clmid, line, ZIP, dates) %>%
  rename(ZIPCODE = ZIP)


# Join data with names of Oregon counties 
oregon_fips <- read_csv('../instructions/oregon_FIPS.csv')
# remove the "County" character
# factor(oregon_fips$county)
oregon_fips$county <- gsub(" County", "", as.character(factor(oregon_fips$county)))

oregon_fips <- oregon_fips %>%
  mutate(st_county_fips = with(oregon_fips, paste0(st_code, fips)))

### Join county with zip
# read_path <- paste0('../data_new/update/or_zip_county_prop.csv') 
# or_zip_county <- read_csv(read_path)

read_path <- paste0('../instructions/oregon_zip_county.csv')
or_zip_county <- read_csv(read_path)

# or_zip_county$county_name[which(or_zip_county$county_name=="Hood.River")] <- "Hood River"

or_zip_county <- or_zip_county %>%
  select(zip, county_name) %>%
  rename(county = county_name) %>%
  rename(ZIPCODE = zip) %>%
  full_join(oregon_fips, by = "county") %>%
  select(ZIPCODE, county, state, st_county_fips) %>%
  rename(fips = st_county_fips) # 484

county_new <- c("Washington", "Douglas", "Lane", "Deschutes")

zip_new <- or_ndc_inhaler %>%
  filter(!(ZIPCODE %in% or_zip_county$ZIPCODE)) %>%
  select(ZIPCODE) %>%
  unique() %>%
  arrange(ZIPCODE) %>%
  mutate(county = county_new)

# summary(as.factor(zip_new$ZIPCODE))
# 97003 97471 97475 97703 
#    48   138     5    16 

or_zip_county_new <- or_zip_county %>%
  select(ZIPCODE, county) %>%
  bind_rows(zip_new)

write_path <- paste0("../data_new/county_data/zip_to_county_new.csv")
write_csv(or_zip_county_new, write_path)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

### import county data
read_path_county_pm <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data_new/county_data/or_county_pop_wt_pm.csv')

county_smoke <- read_csv(read_path_county_pm) # 63801 rows

# descriptives of the two smoke datasets
summary(county_smoke)

county_smoke$county[which(county_smoke$county=="Hood.River")] <- "Hood River"

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
county_smoke_w_lag <- county_smoke %>% arrange(county, date) %>%
  # group by zipcode
  group_by(county) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_pm, 1, order_by = county), 
         wrf_f_pm_lag2 = lag(wrf_pm, 2, order_by = county),
         wrf_f_pm_lag3 = lag(wrf_pm, 3, order_by = county),
         wrf_f_pm_lag4 = lag(wrf_pm, 4, order_by = county),
         wrf_f_pm_lag5 = lag(wrf_pm, 5, order_by = county),
         wrf_f_pm_lag6 = lag(wrf_pm, 6, order_by = county),
         wrf_f_pm_lag7 = lag(wrf_pm, 7, order_by = county),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = county),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = county),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = county),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = county),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = county),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = county),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = county),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = county),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = county),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = county),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = county),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = county),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = county),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = county),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = county),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = county),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = county),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = county),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = county),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = county),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = county),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = county),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = county),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = county),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = county),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = county), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = county),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = county), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = county),
         background_pm_lag2 = lag(background_pm, 2, order_by = county),
         background_pm_lag3 = lag(background_pm, 3, order_by = county),
         background_pm_lag4 = lag(background_pm, 4, order_by = county),
         background_pm_lag5 = lag(background_pm, 5, order_by = county), 
         background_pm_lag6 = lag(background_pm, 6, order_by = county),
         background_pm_lag7 = lag(background_pm, 7, order_by = county), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = county),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = county),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = county),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = county),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = county),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = county),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = county),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = county),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = county),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = county),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = county),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = county),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = county),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = county),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = county),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = county),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = county),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = county),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = county), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = county),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = county)) %>% 
  # ungroup by zip
  ungroup(county) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "county", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(county = county_county, date = date_county, fips = fips_county) %>%
  select(-1)

or_ndc_county_ts <- or_ndc_inhaler %>%
  rename(date = dates) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  # join with county-level population
  left_join(or_zip_county_new, by = "ZIPCODE") %>% # 321 missing 
  filter(!is.na(county)) %>% # no missing value
  left_join(or_pop, by = "county") %>%
  left_join(county_smoke_w_lag, by = c("date", "county")) %>%
  arrange(personkey, date) %>% # order by id and fromdate
  group_by(county, date) %>% 
  # sum up each primary diagnosis for each outcome for each day for each county
  summarise(n_obs = n()) %>% 
  # join daily county estimates of pm2.5
  left_join(county_smoke_w_lag, by = c('date', 'county')) 

# summary(as.factor(or_ndc_county_ts$county)) 

or_ndc_county_ts <- or_ndc_county_ts %>%
  left_join(or_pop, by = "county") %>%
  mutate(geo_smk_pm10 = geo_smk_pm_county/10) %>%
  mutate(rate_per_100k = (n_obs/pop)*100000) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA)))

or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-05-27")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-07-04")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-09-02")] <- "weekend"                           

write_path5 <- paste0("../data_new/medication/or_ndc_county_time_series.csv")
write_csv(or_ndc_county_ts, write_path5)

```



## 1. smoke exposure time series and map of smoke days in Oregon 

### Prepare (already done in previous time stratified work)

1. Make 10 units' geo smoke variable
2. Make county population variable (to calculate rate)
3. Make weekend/weekday variables


```{r time series, warning=FALSE, message=FALSE, echo=FALSE}
read_path5 <- paste0("../data_new/medication/or_ndc_county_time_series.csv")
or_ndc_county_ts <- read_csv(read_path5)

plot_ts <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
           geom_jitter() +
           ylab("Rate of 100k of Beta2 agonist fills") +
           xlab("Year 2013")

print(plot_ts)

# save figure
ggsave("../plot_new/ndc_rate_ts.pdf", plot = plot_ts, 
       width = 12, height = 8, units = "in")


plot_county <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
               geom_jitter() + facet_wrap(~county) +
               ylab("Rate of 100k of Beta2 agonist fills")

plot_county_line <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
                    facet_wrap(~county) + geom_line()

print(plot_county)
# print(plot_county_line)
# save figure
ggsave("../plot_new/ndc_county_rate_ts.pdf", plot = plot_county, 
       width = 12, height = 8, units = "in")
ggsave("../plot_new/ndc_county_rate_ts_line.pdf", plot = plot_county_line, 
       width = 12, height = 8, units = "in")

# plot_smk_ts <- ggplot(or_ndc_county_ts, aes(y =geo_smk_pm10, x = date)) +
#           geom_jitter() +
#           ylab("GWR smoke concentration (10ug/m^3)") +
#           xlab("Year 2013")

# print(plot_smk_ts)

### check if the time series has the association with get smoke
a <- glm(rate_per_100k ~ geo_smk_pm10, data = or_ndc_county_ts, family = "poisson")
# summary(a)

plot_health_smk <- ggplot(or_ndc_county_ts, aes(x = geo_smk_pm10, y = log(rate_per_100k+0.1))) +
  geom_point() + 
  # geom_point(aes(colour = c("red")), alpha = 0.2,  size = 1) + 
  # scale_colour_manual(values = c("red", "blue")) +
  # truncated y axis
  #scale_y_continuous(limits = c(0, 1.5)) +
  # facet_wrap(~county, scale  = "free") +
  ylab("Log Beta 2 agonists Rate per 100,000 Persons") +
  xlab("GWR Smoke PM2.5 per 10ug/m^3") +
  theme_bw()  

# unnecessary
# plot_county_health_smk <- ggplot(or_ndc_county_ts, aes(x = geo_smk_pm10, y = log(rate_per_100k+0.1))) +
#   geom_point(aes(colour = county), alpha = 0.2,  size = 1) + 
  # scale_colour_manual(values = c("red", "blue")) +
  # truncated y axis
  #scale_y_continuous(limits = c(0, 1.5)) +
#   facet_wrap(~county, scale  = "free") +
#   ylab("Log Outcome Rate per 100,000 Persons") +
#   xlab("GWR Smoke PM2.5 per 10*10ug/m^3") +
#   theme_bw()  

plot(plot_health_smk)
# plot(plot_county_health_smk)

ggsave("../plot_new/ndc_rate_health_smk.pdf", plot = plot_health_smk, 
       width = 12, height = 8, units = "in")

# ggsave("../plot_new/ndc_county_rate_health_smk.pdf", plot = plot_county_health_smk, 
#        width = 12, height = 8, units = "in")

```

### map of smoke days

```{r smoke days and map, warning=FALSE, message=FALSE, echo=FALSE}
or_ts <- or_ndc_county_ts %>% 
  mutate(smoke0 = ifelse(geo_smk_pm_county > 0, 1, 0),
         smoke5 = ifelse(geo_smk_pm_county > 5, 1, 0),
         smoke10 = ifelse(geo_smk_pm_county > 10, 1, 0),
         smoke15 = ifelse(geo_smk_pm_county > 15, 1, 0), 
         # lag variable
         geo_smk_lag1 = lag(geo_smk_pm10, 1, order_by = county),
         geo_smk_lag2 = lag(geo_smk_pm10, 2, order_by = county),
         geo_smk_lag3 = lag(geo_smk_pm10, 3, order_by = county),
         geo_smk_lag4 = lag(geo_smk_pm10, 4, order_by = county),
         geo_smk_lag5 = lag(geo_smk_pm10, 5, order_by = county),
         geo_smk_lag6 = lag(geo_smk_pm10, 6, order_by = county),
         geo_smk_lag7 = lag(geo_smk_pm10, 7, order_by = county)) %>% 
  ungroup()

# smoke wave days (at least 2 consecutive days in the 98th percentile of PM)
# quantile(or_ts$geo_wt_pm_county, probs = c(0.95,0.98,0.99, 0.999))
# following Coco's smoke wave day, the 98th percentile for PM2.5 concentrations
# would be >16.3

smoke_wave <- or_ts %>% 
  select(county, date, geo_wt_pm_county) %>% 
  mutate(high_pm_day = ifelse(geo_wt_pm_county > 16.33, 1, 0)) %>% 
  group_by(county) %>% 
  # identify consecutive days
  mutate(smoke_wave = ifelse(lag(high_pm_day, 
    order_by = county)==1 & high_pm_day ==1, 1, 0)) %>% 
  select(-high_pm_day, -geo_wt_pm_county)

# merge in smokewave day
or_ts <- or_ts %>% 
  right_join(smoke_wave, by = c("county", "date"))

# count of state outcome timeseries
state_outcome_rate <- or_ts %>% 
  group_by(date) %>% 
  # remove columns I don't want to calculate
  select(-fips, -county) 
 

# average of environmental measures, joined with outcomes
state_smoke <- or_ts %>% 
  group_by(date) %>% 
  select(-fips, -county) %>% 
  summarise_each(funs(mean, median, min, max), wrf_pm_county:wrf_temp_county) # %>% 
  # full_join(state_outcome_rate, by = c("date"))





# only 55 smoke wave days
# xtabs(~smoke_wave,  or_ts)
# if we compare to our geo smoke > 10, we'd add 362 extra days
# xtabs(~smoke_wave + smoke10, or_ts)
# if we used smoke >15 we'd add 164 extra days 
# xtabs(~smoke_wave + smoke15, or_ts)




# small multiples dataset
or_smk <- or_ts %>% 
  select(county, date, wrf_smk_pm_county, krig_smk_pm_county, geo_smk_pm_county) %>% 
  gather(key = smk_method, value = pm, -date, -county)
  
  
or_smk_plot <- ggplot(or_smk, aes(x = date, y = pm)) +
  geom_point(aes(colour = smk_method), alpha = 0.8, size = 0.8) +
  facet_wrap(~county) +
  ggtitle("Oregon: 2013 Fire Season Smoke PM2.5") +
  ylab("Smoke PM2.5 ug/m^3") +
  xlab("Year: 2013") +
  theme_bw()

or_smk_plot





# data wrangle ----
#first step is to summarise the counts of smoke days in each county 
or_smk_count <- or_ts %>% 
  group_by(county) %>% 
  # summing up smoke days
  summarise(smk_wave_n = sum(smoke_wave), smk_day0 = sum(smoke0), 
            smk_day5 = sum(smoke5), smk_day10 = sum(smoke10),
            smk_day15 = sum(smoke15)) %>% 
  # county needs to be lowercase to join to maps dataframe
  mutate(county = tolower(county))

# maps package will be loaded to pull map data and create a dataframe
or_county_df <- map_data("county", "oregon")

# join county counts to map df
or_smk_df <- or_county_df %>% 
  right_join(or_smk_count, by = c("subregion" = "county")) %>% 
  # small multiples of different smoke cutoff methods
  gather(key = smk_cut_method, value = smoke_days, -long:-subregion) %>% 
  # filter out smoke day 0 since it's not very specific
  filter(smk_cut_method != "smk_day0") %>% 
  # rename smoke day cutoffs 
  mutate(smk_cut_method = 
    ifelse(smk_cut_method == "smk_day5","Smoke PM2.5 > 5 ug/m^3",
    ifelse(smk_cut_method == "smk_day10", "Smoke PM2.5 > 10 ug/m^3",
    ifelse(smk_cut_method == "smk_day15", "Smoke PM2.5 > 15 ug/m^3",
    ifelse(smk_cut_method == "smk_wave_n", "Smoke Wave", NA)))),
    # preserve smoke method order for small multiple
    smk_cut_method = factor(smk_cut_method, 
      levels = c("Smoke PM2.5 > 5 ug/m^3", "Smoke PM2.5 > 10 ug/m^3", 
                 "Smoke PM2.5 > 15 ug/m^3", "Smoke Wave")))

# map ----

# smoke days where GWR smoke > 15
smoke_map <- ggplot(or_smk_df, aes(x=long, y=lat, group=group)) +
  # fill with number of smoke days
  geom_polygon(aes(fill = smoke_days), alpha = 0.7) +
  scale_fill_gradient("Smoke-Impacted Days",
                      low = "#0b486b", high = "#f56217") +
  # add county path on top
  geom_path() +
  facet_wrap(~smk_cut_method) +
  xlab("Longitude") +
  ylab("Latitude") +
  ggtitle("Oregon: Counties affected by smoke") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(colour=NA, fill=NA))

smoke_map

```


## 2. descriptive table of total ndc inhalhers; and age and sex category; Plots

### Descriptives

For all of 2013, there were a total of 77 millon claim records in the APAC dataset. During the May 1st to September 30th wildfire season in Oregon state, there were 24217 pharmacy visits for the ndc of beta 2 agonists. The number of cases, as well as age-specific and sex-specific strate are shown below.

```{r descriptive table, echo = F, message = F, warning = F, results='asis'}
read_path6 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip.csv")
inhaler_ndc <- read_csv(read_path6)
# asthma_ndc <- fread(read_path6, showProgress = T) # faster, but seems error in overall plot analysis

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome_name <- "Beta - 2 agonist"

# dataframe for analysis creation
# bind columns back together 
df_analysis <- inhaler_ndc_df %>%
  filter(!is.na(wrf_smk_pm_zip)) %>% 
  # only look at outcomes
  filter(outcome == 1) %>%
  # add another row that makes sure there is a person <15 in the dataframe
  # tricking xtabs to produce a 0 cell for the outcome for age <15
  add_row(outcome = 0, age_ind = 0)
  
# cross tabs
outcome_n <- xtabs(~ outcome, df_analysis)
cross_tab_age <- xtabs(~ outcome + age_ind, df_analysis)
cross_tab_sex <- xtabs(~ outcome + sex_ind, df_analysis)
# empty matrix
point_estimates <- matrix(nrow = 1, ncol = 7, byrow = T)
  
colnames(point_estimates) <- c("outcome", "n", "age_15", "age_15_65", 
                               "age_65", "female", "male")
  
# fill in the outcome name for the dataframe before the loop
point_estimates[, 1] <- outcome_name
# fill n
point_estimates[, 2] <- outcome_n[2] # second element of the 1 dimension vector
# age <15
point_estimates[, 3] <- cross_tab_age[2, 1]
# age 15 to 65
point_estimates[, 4] <- cross_tab_age[2, 2]
# age >65
point_estimates[, 5] <- cross_tab_age[2, 3]
# male == 0
point_estimates[, 7] <- cross_tab_sex[1, 1]
# female == 1
point_estimates[, 6] <- cross_tab_sex[1, 2]


# save point estimates as a dataframe
point_est_df <- as_data_frame(point_estimates)
  
# combine each outcome dataframe itteration in to a big dataset
asthma_point_est_df <- point_est_df %>% 
  # find proportions/percents for each strata in a row
  mutate(age_15_pr = as.character(round((as.numeric(age_15)/as.numeric(n))*100,1)),
         age_15_65_pr = as.character(round((as.numeric(age_15_65)/as.numeric(n))*100,1)),
         age_65_pr = as.character(round((as.numeric(age_65)/as.numeric(n))*100,1)),
         female_pr = as.character(round((as.numeric(female)/as.numeric(n))*100,1)),
         male_pr = as.character(round((as.numeric(male)/as.numeric(n))*100,1))) %>% 
  select(outcome, n, age_15, age_15_pr, age_15_65, age_15_65_pr, age_65,
         age_65_pr, female, female_pr, male, male_pr)

# str(asthma_point_est_df)
  
tab <- htmlTable(txtRound(asthma_point_est_df, digits = 1), 
           caption = "Total number of cases for pharmacy fills of beta-2 agonist observed from May 1st to September 30st, 2013",
           # column headers
           header = c("Medication", "Cases n", "Less than 15", "(%)", "15 to 65", "(%)", "Greater than 65",
                      "(%)", "Female", "(%)", "Male", "(%)"),
           # column spanner
           cgroup = c("","Age Category", "Sex"), 
           n.cgroup = c(2, 6, 4),
           padding.rgroup = "&nbsp;&nbsp;",
           css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
           align = "llccccc" # column alignment,
            ) # end table

print(tab)

```


### Overall plot with GWR method

The overall plot shows that when smoke concentration increases 10ug/m^3, the risk to get beta-2 agonist fill will increase about 7.5% significantly.

```{r overall, warning =F, echo = F, results='asis'} 
# dataframe list

method_list <- c('Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "Beta - 2 agonists"
outcome_name <- "Beta-2 agonists"

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(91, 93)]/10  # create 10 unit increases

# new loop for age categories

# empty matrix (12 x 10 matrix)
point_estimates <- matrix(nrow = 1, ncol = 9, byrow = T)
    
colnames(point_estimates) <- c('outcome', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
# fill in the outcome namedataframe before method loop
point_estimates[, 1] <- outcome_name

# dataframe for analysis creation
# bind columns back together 
df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
  # remove missing pm values
  filter(!is.na(geo_smk_pm_zip)) %>% 
  # the following code makes sure that the counterfactual values retained are 
  # symetric in that number of obs before = number of obs after
  mutate(obs_diff_admission = (fromdate - date)/7) 
  # dataframe is already for the entire fire season, so I don't need to subset anymore
  
# second loop to run a model for each pm estimation method
j <- 38

# set row number to fill
row_n <- j-37
      
# only run the model if the dataframe has observations
if(nrow(df_analysis) != 0){
  # conditional logistic regression model
  mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
  # populate matrix
  point_estimates[row_n, 2] <- method_list[row_n]
  point_estimates[row_n, 3] <- mod$n
  point_estimates[row_n, 4] <- mod$nevent
  # odds ratio
  point_estimates[row_n, 5] <- round(exp(summary(mod)$coefficient[1,1]), 3)

  # 95% lower bound
  point_estimates[row_n, 6] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
  # 95% upper bound
  point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
  # standard error
  point_estimates[row_n, 8] <- round(summary(mod)$coefficient[1,3], 4)
  # p val
  point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,5], 4)
      
  # create else statement that fills matrix with missing so I still have the row
  # in the final dataframe
  } else {point_estimates[row_n, 2] <- method_list
          point_estimates[row_n, 3] <- 0
          point_estimates[row_n, 4] <- 0
          point_estimates[row_n, c(5:9)] <- 99 } # end 'if else' statement
  
# save point estimates as a dataframe
combined_point_est_df <- as_data_frame(point_estimates)

wrf_geo_age <- combined_point_est_df %>% 
  # subset columns I want to put in to the table
  select(2, 4:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_age, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 three smoke method and pharmacy outcomes",
         # row group by outcome
         rgroup = "Beta - 2 agonist",
         n.rgroup = c(rep(1, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Est Method", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(3, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_age_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95)) %>% 
  # subset columns I want to put in to the table
  select(1, 2, 9, 4:6) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_age_plot$outcome <- factor(wrf_geo_age_plot$outcome,
                              levels = unique(wrf_geo_age_plot$outcome))

wrf_geo_age_plot$pm_method <- factor(wrf_geo_age_plot$pm_method,
                                levels = unique(wrf_geo_age_plot$pm_method))

wrf_geo_age_plot$n_events <- as.numeric(wrf_geo_age_plot$n_events)
wrf_geo_age_plot$odds_ratio <- as.numeric(wrf_geo_age_plot$odds_ratio)
wrf_geo_age_plot$lower95 <- as.numeric(wrf_geo_age_plot$lower95)
wrf_geo_age_plot$upper95 <- as.numeric(wrf_geo_age_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_age_plot,
    aes(x = pm_method, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red",  "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10Âµg/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Smoke Estimation Method') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_overall_gwr.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```


### Time-Stratified by Age Categories 

Following table and figure look at some outcomes stratified by age category. 

For some outcomes, such like Age > 65 in WRF-Chem method, the CI is the only not significant one in the plot.

The plot shows that overall, the risk of pharmacy fills of beta-2 agonist will increase significantly as the smoke concentrate increases. For age group of 15-65, the risk is the highest, for 10 ug/m^3 increase of pm2.5, the risk of filling the beta-2 agonist will increase about 9%. For age groups which are less than 15 or more than 65, the risk is similar, both of them will increase about 5.6%. 

```{r time stratified age strata cdc met, warning =F, echo = F, results='asis'} 
# dataframe list

method_list <- c('Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "Beta - 2 agonists"
outcome_name <- "Beta - 2 agonists"

# age category list
age_cat_list <- c(0,1,2)

# create an empty list to row bind dataframes together
datalist1 <- list()


# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(91, 93)]/10  # create 10 unit increases

# new loop for age categories
for(k in 0:2){
  # empty matrix (12 x 10 matrix)
  point_estimates <- matrix(nrow = 1, ncol = 10, byrow = T)
    
  colnames(point_estimates) <- c('outcome', 'age_cat', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
  # fill in the outcome namedataframe before method loop
  point_estimates[, 1] <- outcome_name
  # repeat the age category 4 times for each pm method
  point_estimates[, 2] <- k
    
  # dataframe for analysis creation
  # bind columns back together 
  df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
    # remove missing pm values
    filter(!is.na(geo_smk_pm_zip)) %>% 
    # limit to specific age category
    filter(age_ind == k) %>% 
    # the following code makes sure that the counterfactual values retained are 
    # symetric in that number of obs before = number of obs after
    mutate(obs_diff_admission = (fromdate - date)/7) 
    # dataframe is already for the entire fire season, so I don't need to subset anymore
  
 j <- 38

    # variable to model 
    var_name <- colnames(df_analysis[j])
      
    # set row number to fill
    row_n <- j-37
      
    # only run the model if the dataframe has observations
    if(nrow(df_analysis) != 0){
    # conditional logistic regression model
    mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
    # populate matrix
    point_estimates[row_n, 3] <- method_list[row_n]
    point_estimates[row_n, 4] <- mod$n
    point_estimates[row_n, 5] <- mod$nevent
    # odds ratio
    point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

    # 95% lower bound
    point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
    # 95% upper bound
    point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
    # standard error
    point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
    # p val
    point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
    # create else statement that fills matrix with missing so I still have the row
    # in the final dataframe
    } else {point_estimates[row_n, 3] <- method_list[row_n]
            point_estimates[row_n, 4] <- 0
            point_estimates[row_n, 5] <- 0
            point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
     # end methods loop
  
  # save point estimates as a dataframe
  point_est_df <- as_data_frame(point_estimates)
  datalist1[[k+1]] <- point_est_df
} # end age category loop

# bind rows of age category estimates together
combined_point_est_df <- bind_rows(datalist1)



wrf_geo_age <- combined_point_est_df %>% 
  # filter columns to just geo-smk
  # filter(pm_method == "GWR Smoke" |
    #      pm_method == "WRF-Chem Smoke") %>% 
  mutate(age_cat2 = ifelse(age_cat == 0, "Less than 15", 
                    ifelse(age_cat == 1, "15-65",
                    ifelse(age_cat == 2, "Greater than 65", NA)))) %>% 
  # subset columns I want to put in to the table
  select(3, 11, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_age, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 geo smoke and health outcomes stratified by age",
         # row group by outcome
         rgroup = "Beta - 2 agonists",
         n.rgroup = c(rep(3, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Est Method", "Age Group", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(4, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Time-stratified: referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_age_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95),
         age_cat2 = ifelse(age_cat == 0, "<15", 
                    ifelse(age_cat == 1, "15-65",
                    ifelse(age_cat == 2, ">65", NA)))) %>% 
  # subset columns I want to put in to the table
  select(1, 3, 11, 10, 5:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_age_plot$outcome <- factor(wrf_geo_age_plot$outcome,
                              levels = unique(wrf_geo_age_plot$outcome))

wrf_geo_age_plot$pm_method <- factor(wrf_geo_age_plot$pm_method,
                                levels = unique(wrf_geo_age_plot$pm_method))

wrf_geo_age_plot$age_cat2 <- factor(wrf_geo_age_plot$age_cat2,
                                levels = unique(wrf_geo_age_plot$age_cat2))

wrf_geo_age_plot$n_events <- as.numeric(wrf_geo_age_plot$n_events)
wrf_geo_age_plot$odds_ratio <- as.numeric(wrf_geo_age_plot$odds_ratio)
wrf_geo_age_plot$lower95 <- as.numeric(wrf_geo_age_plot$lower95)
wrf_geo_age_plot$upper95 <- as.numeric(wrf_geo_age_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_age_plot,
    aes(x = age_cat2, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red",  "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10Âµg/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Age Category ') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10), 
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_age_fig_gwr.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```


### Seasonal Time-Stratified by Sex

The association with smoke PM~2.5~ and health outcomes stratified by sex is shown below. 

All the CI do not include 1, which means the pharmacy filling (beta 2 agonists) increases about 5% when smoke increase 10 units. So the risk for getting asthma will increase about 5% ~ 8% when the smoke PM2.5 increase 10 units. Also, the risk for female is much higher than that for male.

These results show that there might be effect modification by sex, where females might be more likely to fill a beta-2 agonist on the same day it's really smoky for the GWR estimates.

```{r sex strata cdc met adj, warning = F, echo = F, results='asis'} 
method_list <- c('Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "Beta - 2 agonists"
outcome_name <- "Beta - 2 agonists"

# create an empty list to row bind dataframes together
datalist1 <- list()

# sex category list
sex_strata_list <- c(0,1)

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(91, 93)]/10  # create 10 unit increases


# new loop for sex categories
for(k in 0:1){
 
  # empty matrix (12 x 10 matrix)
  point_estimates <- matrix(nrow = 1, ncol = 10, byrow = T)
    
  colnames(point_estimates) <- c('outcome', 'sex', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')
    
  # fill in the outcome namedataframe before method loop
  point_estimates[, 1] <- outcome_name
  # repeat the sex category 4 times for each pm method
  point_estimates[, 2] <- k
    
    
  # dataframe for analysis creation
  # bind columns back together 
  df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
    # remove missing pm values
    filter(!is.na(geo_smk_pm_zip)) %>% 
    # limit to specific sex category
    filter(sex_ind == k) %>% 
    # the following code makes sure that the counterfactual values retained are 
    # symetric in that number of obs before = number of obs after
    mutate(obs_diff_admission = (fromdate - date)/7) 
    # dataframe is already for the entire fire season, so I don't need to subset anymore
  
  j <- 38
    # variable to model 
    var_name <- colnames(df_analysis[j])
      
    # set row number to fill
    row_n <- j-37
      
    # only run the model if the dataframe has observations
    if(nrow(df_analysis) != 0){
    # conditional logistic regression model
    mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
    # populate matrix
    point_estimates[row_n, 3] <- method_list[row_n]
    point_estimates[row_n, 4] <- mod$n
    point_estimates[row_n, 5] <- mod$nevent
    # odds ratio
    point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

    # 95% lower bound
    point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -
                                      1.96*(summary(mod)$coefficient[1,3])), 3)
    # 95% upper bound
    point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                      1.96*(summary(mod)$coefficient[1,3])), 3)
    # standard error
    point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
    # p val
    point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
    # create else statement that fills matrix with missing so I still have the row
    # in the final dataframe
    } else {point_estimates[row_n, 3] <- method_list[row_n]
            point_estimates[row_n, 4] <- 0
            point_estimates[row_n, 5] <- 0
            point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
    # end methods loop
  
  # save point estimates as a dataframe
  point_est_df <- as_data_frame(point_estimates)
    
  # combine previous values in dataframe that has all outcome/methods comparisons
  datalist1[[k+1]] <- point_est_df
} # end sex category loop

# bind rows of sex category estimates together
combined_point_est_df <- bind_rows(datalist1)



wrf_geo_sex <- combined_point_est_df %>% 
  # filter columns to just geo-smk
  # filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  mutate(sex_cat = ifelse(sex == 0, "Male", 
               ifelse(sex == 1, "Female", NA))) %>% 
  # subset columns I want to put in to the table
  select(3, 11, 5:8)%>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


  tab <- htmlTable(txtRound(wrf_geo_sex, digits = 3, 1:3), 
           caption = "Association between a 10 ug/m^3 in PM2.5 geo smoke and pharmacy outcomes stratified by sex",
           # row group by outcome
           rgroup = "Beta - 2 agonists",
           n.rgroup = c(rep(2, 1)), # 2 rows for each sex strata for each outcome
           # column headers
           header = c("Est Method", "Sex Strata", "Events",
                      "OR&dagger;", "Lower", "Upper"),
           # column spanner
           cgroup = c("", "95% CI"), 
           n.cgroup = c(4, 2),
           padding.rgroup = "&nbsp;&nbsp;",
           css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
           align = "llcccc", # column alignment,
           tfoot="&dagger; Time-stratified: referent periods matched to events on same day of week within July to October fire season."
            ) # end table
  
  print(tab)
 
# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_sex_plot <- combined_point_est_df %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | 
   #       pm_method == "WRF-Chem Smoke") %>% 
  mutate(sex_cat = ifelse(sex == 0, "Male", 
               ifelse(sex == 1, "Female", NA))) %>%
  # subset columns I want to put in to the table
  select(1, 3, 11, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))  

# change characters to numeric and factor  
wrf_geo_sex_plot$outcome <- factor(wrf_geo_sex_plot$outcome,
                              levels = unique(wrf_geo_sex_plot$outcome))

wrf_geo_sex_plot$pm_method <- factor(wrf_geo_sex_plot$pm_method,
                                levels = unique(wrf_geo_sex_plot$pm_method))

wrf_geo_sex_plot$sex_cat <- factor(wrf_geo_sex_plot$sex_cat,
                                levels = unique(wrf_geo_sex_plot$sex_cat))

wrf_geo_sex_plot$n_events <- as.numeric(wrf_geo_sex_plot$n_events)
wrf_geo_sex_plot$odds_ratio <- as.numeric(wrf_geo_sex_plot$odds_ratio)
wrf_geo_sex_plot$lower95 <- as.numeric(wrf_geo_sex_plot$lower95)
wrf_geo_sex_plot$upper95 <- as.numeric(wrf_geo_sex_plot$upper95)


## ggplot
  print_plot <- ggplot(wrf_geo_sex_plot,
    aes(x = sex_cat, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red", "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10Âµg/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Sex') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_sex_fig_gwr.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")


```




## 3. Distributed Lag Model

Although the casecrossover study shows a significant association of getting beta-2 agonist pharmacy fills and smoke concentration, we still wonder the association of the pharmacy fills with some lag days. For medication analysis, people could get the pharmacy fills one or some days later than the day they find they have the disease. Then we make 0 (the original day) to 7 lags (one week) to see association of pharmacy fills with different lagged days.

### Find the smallest of AIC with df from 3 to 6

Choose df = 5 because it has the least AIC.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
read_path8 <- paste0("../data_new/county_data/zip_to_county_new.csv")
or_zip_to_county <- read_csv(read_path8)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

inhaler_ndc_lag_df <- inhaler_ndc_df %>%
  left_join(or_zip_to_county, by = "ZIPCODE") %>%
  left_join(or_pop, by = "county") %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  mutate(geo_smk_pm10_zip = geo_smk_pm_zip/10,
         geo_smk_pm10_lag1_zip =geo_smk_pm_lag1_zip/10,
         geo_smk_pm10_lag2_zip =geo_smk_pm_lag2_zip/10,
         geo_smk_pm10_lag3_zip =geo_smk_pm_lag3_zip/10,
         geo_smk_pm10_lag4_zip =geo_smk_pm_lag4_zip/10,
         geo_smk_pm10_lag5_zip =geo_smk_pm_lag5_zip/10,
         geo_smk_pm10_lag6_zip =geo_smk_pm_lag6_zip/10,
         geo_smk_pm10_lag7_zip =geo_smk_pm_lag7_zip/10) 

inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-05-27")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-07-04")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-09-02")] <- "weekend"                           

  
# which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_zip") # 159
# which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_lag1_zip") # 160
# which(colnames(inhaler_ndc_lag_df)=="wrf_temp_zip") # 93
# which(colnames(inhaler_ndc_lag_df)=="wrf_temp_lag1_zip") # 150

inhaler_geo_lag <- inhaler_ndc_lag_df %>%
  select(159, 160:166) # GWR-method
  
inhaler_temp_lag <- inhaler_ndc_lag_df %>%
  select(93, 150:156) # GWR-method


inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)


# create fit matrix
fit_mat <- matrix(NA, nrow=4, ncol=5)
colnames(fit_mat) <- c("outcome", "exposure", "fit", "df", "aic")

# fill outcome name in first column
fit_mat[,1] <- "Beta - 2 agonists"
# fill in exposure (geo smoke)
fit_mat[,2] <- "geo_smk10"
# fit type
fit_mat[,3] <- "ns"
  
# 2 df will not work for a spline, going from 3 to 6 df
  for(h in 3:6){ # start loop for df

    # fitting a natural spline for lag with 5 knots?
    fit_mat[h-2, 4] <- degree_freedom <- h

    # define basis b using natural spline function
    B <- ns(0:7, df = degree_freedom, intercept = T)
    
    # multiply lagged pm matrix by basis
    inhaler_geo_lag_B <- inhaler_geo_lag%*%B
    inhaler_temp_lag_B <- inhaler_temp_lag%*%B

    fit <- clogit(outcome ~ inhaler_geo_lag_B + inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_df)

    AIC(fit)
    
    # fill AIC
    fit_mat[h-2,5] <- round(AIC(fit),5)

    } # end model fit loop
  

# now that we have a range of df/knots, I want to filter to the minimum aic
# for each outcome and print out that value in a table

kable(fit_mat, caption="Distributed lag spline of 3-6 degree of freedom fit by AIC")

lag_spline_best_fit <- as_tibble(fit_mat) %>%  
  slice(which.min(aic)) # df of 3 has the smallest AIC

# kable
knitr::kable(lag_spline_best_fit, caption = paste0("Distributed lag spline ",
  "degree of freedom best fit by AIC"))
```


### Distributed lag 0-7 for casecrossover

When choosing the df of 5, the plot shows that the same day of fill with smoke exposure has the highest significant association. But other lags shows that pharmacy fills with lagged days do not has the significant association with smoke. And the association tends to decrease as lag goes.

```{r DLM for casecrossover df 5, echo = FALSE, message=FALSE, warning=FALSE}
inhaler_geo_lag <- inhaler_ndc_lag_df %>%
  select(159, 160:166) # GWR-method
  
inhaler_temp_lag <- inhaler_ndc_lag_df %>%
  select(93, 150:156) # GWR-method

lag_max <- 7
n1 <- length(inhaler_geo_lag[,1])
n2 <- length(inhaler_temp_lag[,1])

inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)

B <- ns(0:lag_max, df =5, intercept=TRUE) 

# the nrow B should equal ncol(pm)
# dim(B)

inhaler_geo_lag_B <- inhaler_geo_lag%*%B
inhaler_temp_lag_B <- inhaler_temp_lag%*%B

fit <- clogit(outcome ~ inhaler_geo_lag_B + inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_df)

# coef(fit)
# summary(fit)
# AIC(fit)

D <- cbind(B,B)

# dlparms <- grep("inhaler_geo_lag", names(coef(fit)))
dlparms <- c(1,2,3,4,5,6,7,8,9,10)
DLestimate<- data.frame(estimate=D%*%coef(fit)[dlparms]) 
DLvar <- D%*%vcov(fit)[dlparms,dlparms]%*%t(D)
DLestimate$SE <- sqrt(diag(DLvar))
DLestimate$lower <- DLestimate$estimate - DLestimate$SE * 1.96
DLestimate$upper <- DLestimate$estimate + DLestimate$SE * 1.96

DLestimate$estimate <- exp(DLestimate$estimate)
DLestimate$lower <- exp(DLestimate$lower)
DLestimate$upper <- exp(DLestimate$upper)

# DLestimate

DLestimate$lag <- 0:lag_max
p <- ggplot(DLestimate, aes(x=lag, y=estimate, ymin=lower, ymax=upper))
p <- p + geom_ribbon(alpha=.5) + geom_line(size=2)
p <- p + geom_line(aes(x=lag), linetype=2, size=2)
p <- p + theme_bw()
p

DLestimate<- data.frame(estimate=D%*%coef(fit)[dlparms])

cumulative <- sum(DLestimate$estimate)
# cumulative

cumulative_se <- sqrt(sum(DLvar))
# cumulative_se

cumulative_CI <- cumulative + cumulative_se * c(-1.96, 1.96)
# cumulative_CI

cum <- cbind(cumulative, cumulative_se, cumulative_CI[1], cumulative_CI[2])
colnames(cum) <- c("Cumulative Est", "Cumulative SE", "Lower 95% CI", "Upper 95% CI")

knitr::kable(cum, caption = paste0("Distributed lag 0-7 spline estimates, se and CI"))



```


```{r DLM for casecrossover temp, echo = FALSE, message=FALSE, warning=FALSE, eval=FALSE}
read_path8 <- paste0("../data_new/county_data/zip_to_county_new.csv")
or_zip_to_county <- read_csv(read_path8)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

inhaler_ndc_lag_df <- inhaler_ndc_df %>%
  left_join(or_zip_to_county, by = "ZIPCODE") %>%
  left_join(or_pop, by = "county") %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  mutate(geo_smk_pm10_zip = geo_smk_pm_zip/10,
         geo_smk_pm10_lag1_zip =geo_smk_pm_lag1_zip/10,
         geo_smk_pm10_lag2_zip =geo_smk_pm_lag2_zip/10,
         geo_smk_pm10_lag3_zip =geo_smk_pm_lag3_zip/10,
         geo_smk_pm10_lag4_zip =geo_smk_pm_lag4_zip/10,
         geo_smk_pm10_lag5_zip =geo_smk_pm_lag5_zip/10,
         geo_smk_pm10_lag6_zip =geo_smk_pm_lag6_zip/10,
         geo_smk_pm10_lag7_zip =geo_smk_pm_lag7_zip/10) 

inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-05-27")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-07-04")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-09-02")] <- "weekend"                           

  
which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_zip") # 159
which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_lag1_zip") # 160
which(colnames(inhaler_ndc_lag_df)=="wrf_temp_zip") # 93
which(colnames(inhaler_ndc_lag_df)=="wrf_temp_lag1_zip") # 150

inhaler_geo_lag <- inhaler_ndc_lag_df %>%
  select(159, 160:166) # GWR-method
  
inhaler_temp_lag <- inhaler_ndc_lag_df %>%
  select(93, 150:156) # GWR-method

lag_max <- 7
n1 <- length(inhaler_geo_lag[,1])
n2 <- length(inhaler_temp_lag[,1])

inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)

B <- ns(0:lag_max, df =3, intercept=TRUE) 

# the nrow B should equal ncol(pm)
dim(B)

inhaler_geo_lag_B <- inhaler_geo_lag%*%B
inhaler_temp_lag_B <- inhaler_temp_lag%*%B

fit <- clogit(outcome ~  inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_df)

coef(fit)
summary(fit)
AIC(fit)

D <- cbind(B,B)

# dlparms <- grep("inhaler_geo_lag", names(coef(fit)))
dlparms <- c(1,2,3)
DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms]) 
DLvar <- B%*%vcov(fit)[dlparms,dlparms]%*%t(B)
DLestimate$SE <- sqrt(diag(DLvar))
DLestimate$lower <- DLestimate$estimate - DLestimate$SE * 1.96
DLestimate$upper <- DLestimate$estimate + DLestimate$SE * 1.96

DLestimate$estimate <- exp(DLestimate$estimate)
DLestimate$lower <- exp(DLestimate$lower)
DLestimate$upper <- exp(DLestimate$upper)

DLestimate

DLestimate$lag <- 0:lag_max
p <- ggplot(DLestimate, aes(x=lag, y=estimate, ymin=lower, ymax=upper))
p <- p + geom_ribbon(alpha=.5) + geom_line(size=2)
p <- p + geom_line(aes(x=lag), linetype=2, size=2)
p <- p + theme_bw()
p

DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms])

cumulative <- sum(DLestimate$estimate)
cumulative

cumulative_se <- sqrt(sum(DLvar))
cumulative_se

cumulative_CI <- cumulative + cumulative_se * c(-1.96, 1.96)
cumulative_CI


```




### Distributed lag -7 to 0 for casecrossover

Then we make the reversed lag to check with the same df of 5. The plot shows the same result as previous analysis. 

```{r DLM for casecrossover lag -7 to 0 df 5, echo = FALSE, message=FALSE, warning=FALSE}
inhaler_geo_lag <- inhaler_ndc_lag_df %>%
  select(166:160, 159) # GWR-method
  
inhaler_temp_lag <- inhaler_ndc_lag_df %>%
  select(156:150, 93) # GWR-method

lag_max <- 0
n1 <- length(inhaler_geo_lag[,1])
n2 <- length(inhaler_temp_lag[,1])

inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)

B <- ns(-7:0, df =5, intercept=TRUE) 

# the nrow B should equal ncol(pm)
# dim(B)

inhaler_geo_lag_B <- inhaler_geo_lag%*%B
inhaler_temp_lag_B <- inhaler_temp_lag%*%B

fit <- clogit(outcome ~ inhaler_geo_lag_B + inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_df)

# coef(fit)
# summary(fit)
# AIC(fit)

D <- cbind(B,B)

# dlparms <- grep("inhaler_geo_lag", names(coef(fit)))
dlparms <- c(1,2,3,4,5,6,7,8,9,10)
DLestimate<- data.frame(estimate=D%*%coef(fit)[dlparms]) 
DLvar <- D%*%vcov(fit)[dlparms,dlparms]%*%t(D)
DLestimate$SE <- sqrt(diag(DLvar))
DLestimate$lower <- DLestimate$estimate - DLestimate$SE * 1.96
DLestimate$upper <- DLestimate$estimate + DLestimate$SE * 1.96

DLestimate$estimate <- exp(DLestimate$estimate)
DLestimate$lower <- exp(DLestimate$lower)
DLestimate$upper <- exp(DLestimate$upper)

# DLestimate

DLestimate$lag <- -7:0
p <- ggplot(DLestimate, aes(x=lag, y=estimate, ymin=lower, ymax=upper))
p <- p + geom_ribbon(alpha=.5) + geom_line(size=2)
p <- p + geom_line(aes(x=lag), linetype=2, size=2)
p <- p + theme_bw()
p

DLestimate<- data.frame(estimate=D%*%coef(fit)[dlparms])

cumulative <- sum(DLestimate$estimate)
# cumulative

cumulative_se <- sqrt(sum(DLvar))
# cumulative_se

cumulative_CI <- cumulative + cumulative_se * c(-1.96, 1.96)
# cumulative_CI

cum <- cbind(cumulative, cumulative_se, cumulative_CI[1], cumulative_CI[2])
colnames(cum) <- c("Cumulative Est", "Cumulative SE", "Lower 95% CI", "Upper 95% CI")

knitr::kable(cum, caption = paste0("Distributed lag -7 to 0 spline estimates, se and CI"))


```



```{r time stratified zip for casecrossover lag -7 to 0 prepare, echo=FALSE, eval=FALSE}
### Time stratified ------------------------------------------------------------
# read in zipcode level populatoin-weighted pm
read_path5 <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data/Oregon_PM/zip_pm_to_merge_with_acap.csv')

zip_smoke <- read_csv(read_path5) # 63801 rows

# descriptives of the two smoke datasets
summary(zip_smoke)

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
zip_smoke_w_lag <- zip_smoke %>% arrange(ZIPCODE, date) %>%
  # group by zipcode
  group_by(ZIPCODE) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_f_pm, 1, order_by = ZIPCODE), 
         wrf_f_pm_lag2 = lag(wrf_f_pm, 2, order_by = ZIPCODE),
         wrf_f_pm_lag3 = lag(wrf_f_pm, 3, order_by = ZIPCODE),
         wrf_f_pm_lag4 = lag(wrf_f_pm, 4, order_by = ZIPCODE),
         wrf_f_pm_lag5 = lag(wrf_f_pm, 5, order_by = ZIPCODE),
         wrf_f_pm_lag6 = lag(wrf_f_pm, 6, order_by = ZIPCODE),
         wrf_f_pm_lag7 = lag(wrf_f_pm, 7, order_by = ZIPCODE),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = ZIPCODE),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = ZIPCODE),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = ZIPCODE),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = ZIPCODE),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = ZIPCODE),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = ZIPCODE),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = ZIPCODE),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = ZIPCODE),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = ZIPCODE),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = ZIPCODE),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = ZIPCODE),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = ZIPCODE),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = ZIPCODE),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = ZIPCODE),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = ZIPCODE),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = ZIPCODE),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = ZIPCODE),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = ZIPCODE),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = ZIPCODE),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = ZIPCODE),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = ZIPCODE),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = ZIPCODE),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = ZIPCODE),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = ZIPCODE),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = ZIPCODE),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = ZIPCODE), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = ZIPCODE),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = ZIPCODE), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = ZIPCODE),
         background_pm_lag2 = lag(background_pm, 2, order_by = ZIPCODE),
         background_pm_lag3 = lag(background_pm, 3, order_by = ZIPCODE),
         background_pm_lag4 = lag(background_pm, 4, order_by = ZIPCODE),
         background_pm_lag5 = lag(background_pm, 5, order_by = ZIPCODE), 
         background_pm_lag6 = lag(background_pm, 6, order_by = ZIPCODE),
         background_pm_lag7 = lag(background_pm, 7, order_by = ZIPCODE), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = ZIPCODE),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = ZIPCODE),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = ZIPCODE),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = ZIPCODE),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = ZIPCODE),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = ZIPCODE),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = ZIPCODE),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = ZIPCODE),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = ZIPCODE),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = ZIPCODE),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = ZIPCODE),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = ZIPCODE),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = ZIPCODE),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = ZIPCODE),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = ZIPCODE),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = ZIPCODE),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = ZIPCODE),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = ZIPCODE),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = ZIPCODE), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = ZIPCODE),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = ZIPCODE),
         # geo lead
         geo_smk_pm_lag_m1 = lead(geo_smk_pm, 1, order_by = ZIPCODE),
         geo_smk_pm_lag_m2 = lead(geo_smk_pm, 2, order_by = ZIPCODE),
         geo_smk_pm_lag_m3 = lead(geo_smk_pm, 3, order_by = ZIPCODE),
         geo_smk_pm_lag_m4 = lead(geo_smk_pm, 4, order_by = ZIPCODE),
         geo_smk_pm_lag_m5 = lead(geo_smk_pm, 5, order_by = ZIPCODE),
         geo_smk_pm_lag_m6 = lead(geo_smk_pm, 6, order_by = ZIPCODE),
         geo_smk_pm_lag_m7 = lead(geo_smk_pm, 7, order_by = ZIPCODE),
         # temp lead
         wrf_temp_lag_m1 = lead(wrf_temp, 1, order_by = ZIPCODE),
         wrf_temp_lag_m2 = lead(wrf_temp, 2, order_by = ZIPCODE),
         wrf_temp_lag_m3 = lead(wrf_temp, 3, order_by = ZIPCODE),
         wrf_temp_lag_m4 = lead(wrf_temp, 4, order_by = ZIPCODE),
         wrf_temp_lag_m5 = lead(wrf_temp, 5, order_by = ZIPCODE), 
         wrf_temp_lag_m6 = lead(wrf_temp, 6, order_by = ZIPCODE),
         wrf_temp_lag_m7 = lead(wrf_temp, 7, order_by = ZIPCODE)) %>% 
  # ungroup by zip
  ungroup(ZIPCODE) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "zip", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(ZIPCODE = ZIPCODE_zip, date = date_zip)

read_path4 <- paste0("../data_new/medication/oregon_ndc_casecrossover.csv")
# read_path4 <- paste0("../../../data/data_new/oregon_ndc_casecrossover.csv") # for server
or_disease <- read_csv(read_path4)

### try join
colnames(or_disease)[24] <- c("ZIPCODE")
colnames(or_disease)[74] <- c("date")

outcome_casecross <- or_disease %>%
  # indicator for male=0, female=1, unknown = 2
  mutate(age = 2013-yob,
         sex_ind =ifelse(gender == "F", 1, 
                         ifelse(gender == "M", 0, 2)),
         age_ind = ifelse(age < 15, 0,
                          ifelse(age >= 15 & age < 65, 1,
                                 ifelse(age >= 65 & age <=105, 2, NA)))
  ) %>% # end of mutate 
  # create variables
  mutate(day = as.factor(weekdays(fromdate)),
         day_admit = as.factor(weekdays(date)),
         month_smk = month(fromdate),
         month_admit = month(date),
         season_smk = ifelse(fromdate >= "2013-03-20" &  
                               fromdate <= "2013-06-21", "spring",
                             ifelse(fromdate >= "2013-06-22" &  
                                      fromdate <= "2013-09-22", "summer",
                                    ifelse(fromdate >= "2013-09-23" & 
                                             fromdate <= "2013-12-21", "fall", "other"))),
         season_admit = ifelse(date >= "2013-03-20" &  
                                 date <= "2013-06-21", "spring",
                               ifelse(date >= "2013-06-22" &  
                                        date <= "2013-09-22", "summer",
                                      ifelse(date >= "2013-09-23" & 
                                               date <= "2013-12-21", "fall", "other")))) %>%
  # join with zip-level pm estimates
  left_join(zip_smoke_w_lag, by = c("date", "ZIPCODE"))%>%
  arrange(personkey, fromdate) # order by id and fromdate

write_path4 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip_lag15.csv")
write_csv(outcome_casecross, write_path4)

```

```{r time stratified county for ts lag -7 to 0 prepare, echo=FALSE, include=FALSE, eval=FALSE}
read_path7 <- paste0("../data_new/medication/oregon_asthma_ndc.csv")
or_ndc_claim <- read_csv(read_path7)

or_ndc_inhaler <- or_ndc_claim %>%
  select(personkey, num_visit, clmid, line, ZIP, dates) %>%
  rename(ZIPCODE = ZIP)


# Join data with names of Oregon counties 
oregon_fips <- read_csv('../instructions/oregon_FIPS.csv')
# remove the "County" character
# factor(oregon_fips$county)
oregon_fips$county <- gsub(" County", "", as.character(factor(oregon_fips$county)))

oregon_fips <- oregon_fips %>%
  mutate(st_county_fips = with(oregon_fips, paste0(st_code, fips)))

### Join county with zip
# read_path <- paste0('../data_new/update/or_zip_county_prop.csv') 
# or_zip_county <- read_csv(read_path)

read_path <- paste0('../instructions/oregon_zip_county.csv')
or_zip_county <- read_csv(read_path)

# or_zip_county$county_name[which(or_zip_county$county_name=="Hood.River")] <- "Hood River"

or_zip_county <- or_zip_county %>%
  select(zip, county_name) %>%
  rename(county = county_name) %>%
  rename(ZIPCODE = zip) %>%
  full_join(oregon_fips, by = "county") %>%
  select(ZIPCODE, county, state, st_county_fips) %>%
  rename(fips = st_county_fips) # 484

county_new <- c("Washington", "Douglas", "Lane", "Deschutes")

zip_new <- or_ndc_inhaler %>%
  filter(!(ZIPCODE %in% or_zip_county$ZIPCODE)) %>%
  select(ZIPCODE) %>%
  unique() %>%
  arrange(ZIPCODE) %>%
  mutate(county = county_new)

# summary(as.factor(zip_new$ZIPCODE))
# 97003 97471 97475 97703 
#    48   138     5    16 

or_zip_county_new <- or_zip_county %>%
  select(ZIPCODE, county) %>%
  bind_rows(zip_new)

write_path <- paste0("../data_new/county_data/zip_to_county_new.csv")
write_csv(or_zip_county_new, write_path)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

### import county data
read_path_county_pm <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data_new/county_data/or_county_pop_wt_pm.csv')

county_smoke <- read_csv(read_path_county_pm) # 63801 rows

# descriptives of the two smoke datasets
summary(county_smoke)

county_smoke$county[which(county_smoke$county=="Hood.River")] <- "Hood River"

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
county_smoke_w_lag <- county_smoke %>% arrange(county, date) %>%
  # group by zipcode
  group_by(county) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_pm, 1, order_by = county), 
         wrf_f_pm_lag2 = lag(wrf_pm, 2, order_by = county),
         wrf_f_pm_lag3 = lag(wrf_pm, 3, order_by = county),
         wrf_f_pm_lag4 = lag(wrf_pm, 4, order_by = county),
         wrf_f_pm_lag5 = lag(wrf_pm, 5, order_by = county),
         wrf_f_pm_lag6 = lag(wrf_pm, 6, order_by = county),
         wrf_f_pm_lag7 = lag(wrf_pm, 7, order_by = county),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = county),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = county),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = county),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = county),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = county),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = county),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = county),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = county),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = county),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = county),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = county),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = county),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = county),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = county),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = county),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = county),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = county),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = county),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = county),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = county),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = county),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = county),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = county),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = county),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = county),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = county), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = county),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = county), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = county),
         background_pm_lag2 = lag(background_pm, 2, order_by = county),
         background_pm_lag3 = lag(background_pm, 3, order_by = county),
         background_pm_lag4 = lag(background_pm, 4, order_by = county),
         background_pm_lag5 = lag(background_pm, 5, order_by = county), 
         background_pm_lag6 = lag(background_pm, 6, order_by = county),
         background_pm_lag7 = lag(background_pm, 7, order_by = county), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = county),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = county),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = county),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = county),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = county),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = county),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = county),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = county),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = county),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = county),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = county),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = county),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = county),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = county),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = county),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = county),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = county),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = county),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = county), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = county),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = county),
          # geo lead
         geo_smk_pm_lag_m1 = lead(geo_smk_pm, 1, order_by = county),
         geo_smk_pm_lag_m2 = lead(geo_smk_pm, 2, order_by = county),
         geo_smk_pm_lag_m3 = lead(geo_smk_pm, 3, order_by = county),
         geo_smk_pm_lag_m4 = lead(geo_smk_pm, 4, order_by = county),
         geo_smk_pm_lag_m5 = lead(geo_smk_pm, 5, order_by = county),
         geo_smk_pm_lag_m6 = lead(geo_smk_pm, 6, order_by = county),
         geo_smk_pm_lag_m7 = lead(geo_smk_pm, 7, order_by = county),
         # temp lead
         wrf_temp_lag_m1 = lead(wrf_temp, 1, order_by = county),
         wrf_temp_lag_m2 = lead(wrf_temp, 2, order_by = county),
         wrf_temp_lag_m3 = lead(wrf_temp, 3, order_by = county),
         wrf_temp_lag_m4 = lead(wrf_temp, 4, order_by = county),
         wrf_temp_lag_m5 = lead(wrf_temp, 5, order_by = county), 
         wrf_temp_lag_m6 = lead(wrf_temp, 6, order_by = county),
         wrf_temp_lag_m7 = lead(wrf_temp, 7, order_by = county)) %>% 
  # ungroup by zip
  ungroup(county) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "county", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(county = county_county, date = date_county, fips = fips_county) %>%
  select(-1)

or_ndc_county_ts <- or_ndc_inhaler %>%
  rename(date = dates) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  # join with county-level population
  left_join(or_zip_county_new, by = "ZIPCODE") %>% # 321 missing 
  filter(!is.na(county)) %>% # no missing value
  left_join(or_pop, by = "county") %>%
  left_join(county_smoke_w_lag, by = c("date", "county")) %>%
  arrange(personkey, date) %>% # order by id and fromdate
  group_by(county, date) %>% 
  # sum up each primary diagnosis for each outcome for each day for each county
  summarise(n_obs = n()) %>% 
  # join daily county estimates of pm2.5
  left_join(county_smoke_w_lag, by = c('date', 'county')) 

# summary(as.factor(or_ndc_county_ts$county)) 

or_ndc_county_ts <- or_ndc_county_ts %>%
  left_join(or_pop, by = "county") %>%
  mutate(geo_smk_pm10 = geo_smk_pm_county/10) %>%
  mutate(rate_per_100k = (n_obs/pop)*100000) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA)))

or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-05-27")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-07-04")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-09-02")] <- "weekend"                           

write_path5 <- paste0("../data_new/medication/or_ndc_county_time_series_lag15.csv")
write_csv(or_ndc_county_ts, write_path5)

```


```{r time stratified zip for casecrossover lag -7 to 0 df, echo=FALSE, include=FALSE, eval=FALSE}
read_path10 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip_lag15.csv")
inhaler_ndc_lag15 <- read_csv(read_path10)
# asthma_ndc <- fread(read_path6, showProgress = T) # faster, but seems error in overall plot analysis

# dataframe to loop through
inhaler_ndc_lag15_df <- data.frame(inhaler_ndc_lag15)

inhaler_ndc_lag_15_df <- inhaler_ndc_lag15_df %>%
  mutate(geo_smk_pm10_lag_m1_zip =geo_smk_pm_lag_m1_zip/10,
         geo_smk_pm10_lag_m2_zip =geo_smk_pm_lag_m2_zip/10,
         geo_smk_pm10_lag_m3_zip =geo_smk_pm_lag_m3_zip/10,
         geo_smk_pm10_lag_m4_zip =geo_smk_pm_lag_m4_zip/10,
         geo_smk_pm10_lag_m5_zip =geo_smk_pm_lag_m5_zip/10,
         geo_smk_pm10_lag_m6_zip =geo_smk_pm_lag_m6_zip/10,
         geo_smk_pm10_lag_m7_zip =geo_smk_pm_lag_m7_zip/10) %>%
  mutate(geo_smk_pm10_zip = geo_smk_pm_zip/10,
         geo_smk_pm10_lag1_zip =geo_smk_pm_lag1_zip/10,
         geo_smk_pm10_lag2_zip =geo_smk_pm_lag2_zip/10,
         geo_smk_pm10_lag3_zip =geo_smk_pm_lag3_zip/10,
         geo_smk_pm10_lag4_zip =geo_smk_pm_lag4_zip/10,
         geo_smk_pm10_lag5_zip =geo_smk_pm_lag5_zip/10,
         geo_smk_pm10_lag6_zip =geo_smk_pm_lag6_zip/10,
         geo_smk_pm10_lag7_zip =geo_smk_pm_lag7_zip/10) 
  
# which(colnames(inhaler_ndc_lag_15_df)=="geo_smk_pm10_zip") # 178
# which(colnames(inhaler_ndc_lag_15_df)=="geo_smk_pm10_lag_m1_zip") # 171
# which(colnames(inhaler_ndc_lag_15_df)=="geo_smk_pm10_lag1_zip") # 179

# which(colnames(inhaler_ndc_lag_15_df)=="wrf_temp_zip") # 93
# which(colnames(inhaler_ndc_lag_15_df)=="wrf_temp_lag1_zip") # 150
# which(colnames(inhaler_ndc_lag_15_df)=="wrf_temp_lag_m1_zip") # 164

inhaler_geo_lag <- inhaler_ndc_lag_15_df %>%
  select(177:171, 178) # GWR-method
  
inhaler_temp_lag <- inhaler_ndc_lag_15_df %>%
  select(170:164, 93) # temp

inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)

# create fit matrix
fit_mat <- matrix(NA, nrow=4, ncol=5)
colnames(fit_mat) <- c("outcome", "exposure", "fit", "df", "aic")

# fill outcome name in first column
fit_mat[,1] <- "Beta - 2 agonists"
# fill in exposure (geo smoke)
fit_mat[,2] <- "geo_smk10"
# fit type
fit_mat[,3] <- "ns"
  
# 2 df will not work for a spline, going from 3 to 6 df
  for(h in 3:6){ # start loop for df

    # fitting a natural spline for lag with 5 knots?
    fit_mat[h-2, 4] <- degree_freedom <- h

    # define basis b using natural spline function
    B <- ns(-7:0, df = degree_freedom, intercept = T)
    
    inhaler_geo_lag_B <- inhaler_geo_lag%*%B
    inhaler_temp_lag_B <- inhaler_temp_lag%*%B

    fit <- clogit(outcome ~ inhaler_geo_lag_B + inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_15_df)

    AIC(fit)
    
    # fill AIC
    fit_mat[h-2,5] <- round(AIC(fit),5)

    } # end model fit loop
  

# now that we have a range of df/knots, I want to filter to the minimum aic
# for each outcome and print out that value in a table

fit_mat

lag_spline_best_fit <- as_tibble(fit_mat) %>%  
  slice(which.min(aic)) # df of 3 has the smallest AIC

# kable
knitr::kable(lag_spline_best_fit, caption = paste0("Distributed lag spline",
  "degree of freedom best fit by AIC for mixed model approach"))

```







## Supplement
### 1. For Overall Plot (Unconstrained lag model)

```{r overall lags, warning =F, echo = F, results='asis'} 
# dataframe list
method_list <- c('Geo-Weighted Smoke')

lag_list <- c("Lag 1", "Lag 2", "Lag 3", "Lag 4", "Lag 5", "Lag 6", "Lag 7")

# dataframe to loop through
inhaler_ndc <- data.frame(inhaler_ndc) 
#  filter(!is.na(geo_smk_pm_lag1_zip))

# outcome name
outcome <- "Beta - 2 agonists"

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc[, c(1:26, 74:79)] # 94:156 is lag
  
# extract pm values and divide by 10 and ordered
# which(colnames(inhaler_ndc)=="geo_smk_pm_lag1_zip") # 136
# which(colnames(inhaler_ndc)=="wrf_temp_lag1_zip") # 150
pm_estimates_df <- inhaler_ndc[, 136:142]/10  # create 10 unit increases
temp_estimates_df <- inhaler_ndc[, 150:156]  # temperature

# new loop for age categories

# empty matrix (12 x 10 matrix)
point_estimates <- matrix(nrow = 7, ncol = 10, byrow = T)
    
colnames(point_estimates) <- c('outcome', 'pm_method',  'lag', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
# fill in the outcome namedataframe before method loop
point_estimates[, 1] <- outcome

for (i in 1:7){
geo_lag <- i + 32 
temp_lag <- i + 39

# dataframe for analysis creation
# bind columns back together 
df_analysis <- cbind(covariates_df, pm_estimates_df, temp_estimates_df) 

df_analysis <- df_analysis %>% 
  # remove missing pm values
  filter(!is.na(df_analysis[geo_lag])) %>% 
  # the following code makes sure that the counterfactual values retained are 
  # symetric in that number of obs before = number of obs after
  mutate(obs_diff_admission = (fromdate - date)/7) 
  # dataframe is already for the entire fire season, so I don't need to subset anymore
  
# second loop to run a model for each pm estimation method


  # variable to model 
  var_name <- colnames(df_analysis[geo_lag])
      
  # set row number to fill
  row_n <- i
      
  # only run the model if the dataframe has observations
  if(nrow(df_analysis) != 0){
  # conditional logistic regression model
  mod <- clogit(outcome ~ df_analysis[[geo_lag]] + df_analysis[[temp_lag]] + strata(personkey), df_analysis)
      
  # populate matrix
  point_estimates[row_n, 2] <- method_list
  point_estimates[row_n, 3] <- lag_list[row_n]
  point_estimates[row_n, 4] <- mod$n
  point_estimates[row_n, 5] <- mod$nevent
  # odds ratio
  point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

  # 95% lower bound
  point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
  # 95% upper bound
  point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
  # standard error
  point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
  # p val
  point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
  # create else statement that fills matrix with missing so I still have the row
  # in the final dataframe
  } else {point_estimates[row_n, 3] <- method_list[row_n]
          point_estimates[row_n, 4] <- 0
          point_estimates[row_n, 5] <- 0
          point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
  
}
# save point estimates as a dataframe
combined_point_est_df <- as_data_frame(point_estimates)



wrf_geo_lag <- combined_point_est_df %>% 
  select(3, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_lag, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 three smoke method and pharmacy outcomes",
         # row group by outcome
         rgroup = "Beta - 2 agonists",
         n.rgroup = c(rep(1, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Lag", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(3, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_lag_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95)) %>% 
  # subset columns I want to put in to the table
  select(1, 3, 10, 5:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_lag_plot$outcome <- factor(wrf_geo_lag_plot$outcome,
                              levels = unique(wrf_geo_lag_plot$outcome))

wrf_geo_lag_plot$lag <- factor(wrf_geo_lag_plot$lag,
                                levels = unique(wrf_geo_lag_plot$lag))

wrf_geo_lag_plot$n_events <- as.numeric(wrf_geo_lag_plot$n_events)
wrf_geo_lag_plot$odds_ratio <- as.numeric(wrf_geo_lag_plot$odds_ratio)
wrf_geo_lag_plot$lower95 <- as.numeric(wrf_geo_lag_plot$lower95)
wrf_geo_lag_plot$upper95 <- as.numeric(wrf_geo_lag_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_lag_plot,
    aes(x = lag, y = odds_ratio, color = lag), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Geo-smk Lag", 
                       values = rep(c("black"), 7),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 7, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10Âµg/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Smoke Estimation Method') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_health_lag.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```

### 2. Unconstrained lag for time series

```{r unconstrained ts lag, message=FALSE, echo=FALSE, warning=FALSE}
or_ndc_county_ts_df <- or_ndc_county_ts %>%
  select(1:4, pop, rate_per_100k, day, geo_smk_pm_county,
         geo_smk_pm_lag1_county:geo_smk_pm_lag7_county, wrf_temp_county,
         wrf_temp_lag1_county:wrf_temp_lag7_county) %>%
  mutate(geo_smk_pm10_county = geo_smk_pm_county/10,
         geo_smk_pm10_lag1_county =geo_smk_pm_lag1_county/10,
         geo_smk_pm10_lag2_county =geo_smk_pm_lag2_county/10,
         geo_smk_pm10_lag3_county =geo_smk_pm_lag3_county/10,
         geo_smk_pm10_lag4_county =geo_smk_pm_lag4_county/10,
         geo_smk_pm10_lag5_county =geo_smk_pm_lag5_county/10,
         geo_smk_pm10_lag6_county =geo_smk_pm_lag6_county/10,
         geo_smk_pm10_lag7_county =geo_smk_pm_lag7_county/10) 
  # filter(!is.na(geo_smk_pm10_lag7_zip))

# create empty dataframe
rr_df <- data.frame(matrix(nrow = 7, ncol = 5))
colnames(rr_df) <- c("method", "lag", "rel_risk", "lower_95", "upper_95")

# vector of outcomes
outcome_list <- "n_obs"

# methods
rr_df[,1] <- c("Mixed-Poisson")

# populate outcome column
rr_df[,2] <- c("Lag 1", "Lag 2", "Lag 3", "Lag 4", "Lag 5", "Lag 6", "Lag 7")

# which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_lag1_county") #25
# which(colnames(or_ndc_county_ts_df)=="wrf_temp_lag1_county") #17

for (i in 1:7){
  
  geo <- i + 24
  tem <- i +14
  
## mixed
smk_est_mp <- tidy(glmer(as.formula(paste0(outcome_list, 
    "~ or_ndc_county_ts_df[[geo]] + or_ndc_county_ts_df[[tem]] + (1|county) + day + offset(log(pop))")), 
    or_ndc_county_ts_df, family="poisson"))[2, ]

rr_mp <- c(round(exp(smk_est_mp[1,2]),5),
         round(exp(smk_est_mp[1,2]-1.96*smk_est_mp[1,3]),5),
         round(exp(smk_est_mp[1,2]+1.96*smk_est_mp[1,3]),5))

rr_df[i,3:5] <- rr_mp
}

kable(rr_df, caption = "Unconstrained lag for time series")

plot_rr <- ggplot(rr_df, aes(x=lag, y = rel_risk)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower_95, ymax=upper_95), width = 0.2) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  theme(
   panel.background = element_rect(fill = 'white', colour = 'black'),
   panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(),
   axis.text.x = element_text(angle = 90, vjust = .75)) +
  ylab("Relative Risk") +
  xlab("Outcome") +
  ggtitle("Relative Risk for a 10ug/m^3 increase PM2.5 estimated via GWR Smoke")

print(plot_rr)

ggsave("../plot_new/ndc_rr_geo_lag.pdf", plot = plot_rr, 
       width = 12, height = 8, units = "in")

```

### 3. Distributed lag check for time series 

(not shown)

```{r DLM ts, echo = FALSE, message=FALSE, warning=FALSE, eval=FALSE}
which(colnames(or_ndc_county_ts_df)=="wrf_temp_lag1_county") # 17
which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_lag1_county") # 25

geo_ts_lag <- or_ndc_county_ts_df %>%
  select(24:31) # GWR-method
tem_ts_lag <- or_ndc_county_ts_df %>%
  select(16:23) # temp

lag_max <- 7

geo_ts_lag <- as.matrix(geo_ts_lag)
tem_ts_lag <- as.matrix(tem_ts_lag)

B <- ns(0:lag_max, df =3, intercept=TRUE) # or 3?

# the nrow B should equal ncol(pm)
dim(B)
dim(geo_ts_lag)
dim(tem_ts_lag)

geo_ts_lag_B <- geo_ts_lag%*%B 

tem_ts_lag_B <- tem_ts_lag%*%B

## mixed model
mod <-glmer(n_obs ~  geo_ts_lag_B + tem_ts_lag_B + day + (1|county) + offset(log(pop)),   
            or_ndc_county_ts_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))

summary(mod)
# check AIC
AIC(mod)

D <- cbind(B, B)
# output distributed lag beta parameters
dlparms <- mod@beta[2:7]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = D %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:7,2:7]) 

# estimate variance of splines
dl_var <- D%*%cov_mat%*%t(D)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p
```

```{r DLM ts temp, echo = FALSE, message=FALSE, warning=FALSE, eval=FALSE}
which(colnames(or_ndc_county_ts_df)=="wrf_temp_lag1_county") # 17
which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_lag1_county") # 25

geo_ts_lag <- or_ndc_county_ts_df %>%
  select(24:31) # GWR-method

lag_max <- 7

geo_ts_lag <- as.matrix(geo_ts_lag)
tem_ts_lag <- as.matrix(tem_ts_lag)

B <- ns(0:lag_max, df =3, intercept=TRUE) # or 3?

# the nrow B should equal ncol(pm)
dim(B)
dim(tem_ts_lag)

tem_ts_lag_B <- tem_ts_lag%*%B

## mixed model
mod <-glmer(n_obs ~ tem_ts_lag_B + day + (1|county) + offset(log(pop)),   
            or_ndc_county_ts_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))

summary(mod)
# check AIC
AIC(mod)

# output distributed lag beta parameters
dlparms <- mod@beta[2:4]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = B %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:4,2:4]) 

# estimate variance of splines
dl_var <- B%*%cov_mat%*%t(B)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p
```

### 4. Distributed lag -7 to 0 for time series

(not shown)

```{r DLM for casecrossover lag -7 to 0 temp, echo = FALSE, message=FALSE, warning=FALSE, eval = FALSE}

inhaler_temp_lag <- inhaler_ndc_lag_15_df %>%
  select(170:164, 93, 150:156) # temp

lag_max <- 7

inhaler_geo_lag <- as.matrix(inhaler_geo_lag)
inhaler_temp_lag <- as.matrix(inhaler_temp_lag)

B <- ns(-7:lag_max, df =3, intercept=TRUE) 

# the nrow B should equal ncol(pm)
dim(B)

inhaler_temp_lag_B <- inhaler_temp_lag%*%B

fit <- clogit(outcome ~  inhaler_temp_lag_B + strata(personkey), 
              inhaler_ndc_lag_15_df)

coef(fit)
summary(fit)
AIC(fit)

# dlparms <- grep("inhaler_geo_lag", names(coef(fit)))
dlparms <- c(1,2,3)
DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms]) 
DLvar <- B%*%vcov(fit)[dlparms,dlparms]%*%t(B)
DLestimate$SE <- sqrt(diag(DLvar))
DLestimate$lower <- DLestimate$estimate - DLestimate$SE * 1.96
DLestimate$upper <- DLestimate$estimate + DLestimate$SE * 1.96

DLestimate$estimate <- exp(DLestimate$estimate)
DLestimate$lower <- exp(DLestimate$lower)
DLestimate$upper <- exp(DLestimate$upper)

DLestimate

DLestimate$lag <- -7:lag_max
p <- ggplot(DLestimate, aes(x=lag, y=estimate, ymin=lower, ymax=upper))
p <- p + geom_ribbon(alpha=.5) + geom_line(size=2)
p <- p + geom_line(aes(x=lag), linetype=2, size=2)
p <- p + theme_bw()
p

DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms])

cumulative <- sum(DLestimate$estimate)
cumulative

cumulative_se <- sqrt(sum(DLvar))
cumulative_se

cumulative_CI <- cumulative + cumulative_se * c(-1.96, 1.96)
cumulative_CI

```

```{r DLM ts -7 to 0, echo = FALSE, message=FALSE, warning=FALSE, eval=FALSE}
read_path11 <- paste0("../data_new/medication/or_ndc_county_time_series_lag15.csv")
or_ndc_county_ts_lag15 <- read_csv(read_path11)

or_ndc_county_ts_df <- or_ndc_county_ts_lag15 %>%
  select(1:4, pop, rate_per_100k, day,  geo_smk_pm_lag_m1_county:geo_smk_pm_lag_m7_county, geo_smk_pm_county,
         geo_smk_pm_lag1_county:geo_smk_pm_lag7_county, wrf_temp_lag_m1_county:wrf_temp_lag_m7_county, 
         wrf_temp_county, wrf_temp_lag1_county:wrf_temp_lag7_county) %>%
  mutate(geo_smk_pm10_county = geo_smk_pm_county/10,
         geo_smk_pm10_lag1_county =geo_smk_pm_lag1_county/10,
         geo_smk_pm10_lag2_county =geo_smk_pm_lag2_county/10,
         geo_smk_pm10_lag3_county =geo_smk_pm_lag3_county/10,
         geo_smk_pm10_lag4_county =geo_smk_pm_lag4_county/10,
         geo_smk_pm10_lag5_county =geo_smk_pm_lag5_county/10,
         geo_smk_pm10_lag6_county =geo_smk_pm_lag6_county/10,
         geo_smk_pm10_lag7_county =geo_smk_pm_lag7_county/10,
         # lag -7 to -1
         geo_smk_pm10_lag_m1_county =geo_smk_pm_lag_m1_county/10,
         geo_smk_pm10_lag_m2_county =geo_smk_pm_lag_m2_county/10,
         geo_smk_pm10_lag_m3_county =geo_smk_pm_lag_m3_county/10,
         geo_smk_pm10_lag_m4_county =geo_smk_pm_lag_m4_county/10,
         geo_smk_pm10_lag_m5_county =geo_smk_pm_lag_m5_county/10,
         geo_smk_pm10_lag_m6_county =geo_smk_pm_lag_m6_county/10,
         geo_smk_pm10_lag_m7_county =geo_smk_pm_lag_m7_county/10)

which(colnames(or_ndc_county_ts_df)=="wrf_temp_lag1_county") # 31
which(colnames(or_ndc_county_ts_df)=="wrf_temp_county") # 30
which(colnames(or_ndc_county_ts_df)=="wrf_temp_lag_m1_county") # 23
which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_lag1_county") # 39
which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_lag_m1_county") # 46
which(colnames(or_ndc_county_ts_df)=="geo_smk_pm10_county") # 38


geo_ts_lag <- or_ndc_county_ts_df %>%
  select(52:46, 38, 39:45) # GWR-method
tem_ts_lag <- or_ndc_county_ts_df %>%
  select(29:23, 30, 31:37) # temp

lag_max <- 7

geo_ts_lag <- as.matrix(geo_ts_lag)
tem_ts_lag <- as.matrix(tem_ts_lag)

B <- ns(-7:lag_max, df =3, intercept=TRUE) # or 3?

# the nrow B should equal ncol(pm)
dim(B)
dim(geo_ts_lag)
dim(tem_ts_lag)

geo_ts_lag_B <- geo_ts_lag%*%B 

tem_ts_lag_B <- tem_ts_lag%*%B

## mixed model
mod <-glmer(n_obs ~  geo_ts_lag_B + tem_ts_lag_B + day + (1|county) + offset(log(pop)),   
            or_ndc_county_ts_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))

summary(mod)
# check AIC
AIC(mod)

D <- cbind(B, B)
# output distributed lag beta parameters
dlparms <- mod@beta[2:7]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = D %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:7,2:7]) 

# estimate variance of splines
dl_var <- D%*%cov_mat%*%t(D)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = -7:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p


```


