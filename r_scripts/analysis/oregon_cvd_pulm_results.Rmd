---
title: "Douglas-complex fire smoke and cardiopulmonary morbidity"
author: "Ryan Gan"
date: "11/3/2017"
output: html_document
---

##1. Introduction

In the summer of 2013, the Douglas-Complex fires occured in southwest Oregon. Oregonians in this part of the state were at risk of exposure to extreme levels of particulate matter (PM). This project aim is to determine if there is an association to smoke from the Douglas-Complex fires and acute cardiopulmonary morbidity in the state of Oregon.

Data came from the Oregon All Payer All Claims Database (APAC) in the year 2013. The APAC records the health care billing data for Oregon's insured populations. APAC include individual billing records for both diagnoses codes (International Classification of Diseases, Clinical Modification (ICD-9-CM) diagnoses codes) and pharmacy codes (National Drug Codes (NDC)). 

Our previous research that found an association with wildfire smoke and respiratory outcomes in Washington state in 2012 wildfire season using a novel estimate of smoke concentration, geographically weighted ridge regression (GWR) guided the methodological approaches used in this project. As Oregon contains pharmacy records, we evaluate the association between smoke and respiratory rescue medications (beta 2 agonists) (abbreviate to SABA). 

*Research question*
We evaluated the association between smoke concentrations using the GWR method and cardiopulmonary morbidity, including ED/urgent care visits and SABA fills in Oregon state during the 2013 wildfire season.

This markdown document contains the code and results that were used to address this research question.

Packages used: tidyverse, survival.
```{r setup, echo =F}
library(tidyverse) # general data wrangle
library(survival) # conditional logistic regression

# knitr options
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```


##2. Wildfire smoke descriptive characteristics

Importing ZIP code-level population-weighted PM~2.5~ daily data.

```{r smoke data import and wrangle}
# pm path
pm_path <- paste0("../../data/pm/2013-oregon_county_pm25.csv")
# county pm
county_pm_df <- read_csv(pm_path) %>% 
  mutate(county = stringr::str_replace(county, "[.]", ""))

# estimate county smoke 
county_smk_count <- county_pm_df %>% 
  # binary smoke variable at >10 ug/m^3
  mutate(gwr_smk10 = ifelse(geo_smk_pm >= 10, 1, 0)) %>% 
  group_by(county) %>% 
  summarise(smk_day10 = sum(gwr_smk10)) %>% 
  # lower case county name and remove "." to match spatial df
  mutate(subregion = tolower(stringr::str_replace(county, "[.]", " ")))

# extract oregon map data
or_county_spatial_df <- map_data("county", "oregon") %>% 
  right_join(county_smk_count, by = "subregion")

# use the map function from the maps package to get the polygon data
county_poly <- maps::map("county", "oregon", plot=FALSE, fill = TRUE)
# find centroids
county_centroids <- maps:::apply.polygon(county_poly, maps:::centroid.polygon)

# create a data frame for graphing out of the centroids of each polygon
county_centroids <- county_centroids[!is.na(names(county_centroids))]
centroid_array <- Reduce(rbind, county_centroids)

county_text <- reduce(county_centroids, rbind) %>% 
  as_data_frame() %>% 
  rename(long = V1, lat = V2) %>% 
  mutate(county = stringr::str_sub(
    stringr::str_to_title(names(county_centroids)), start=8L)) 
```

### Number of days in Oregon where smoke PM~2.5~ exceeded 10 ug/m^3. 

```{r smoke days map}
smoke_map <- ggplot(or_county_spatial_df, aes(x=long,y=lat, group=group)) +
  # fill with number of smoke days
  geom_polygon(aes(fill =smk_day10)) +
  scale_fill_gradient(expression("Smoke Days > 10 µg/m"^3),
    low= "#3B9AB2", high="#F21A00", 
    guide = guide_colorbar(direction="horizontal", title.position = "top",
                           title.hjust = 0.5, barwidth = 20)) +
  # add county path on top
  geom_path(colour="#EBCC2A") +
  # add county text 
  geom_text(data = county_text, aes(x=long, y=lat, label = county, group=NULL), 
    colour = "white", size = 2) +
  xlab("Longitude") +
  ylab("Latitude") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    strip.text = element_text(size = 8),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(colour=NA, fill=NA),
    legend.position = "bottom")

smoke_map
```

Most of the heavy smoke days were in the south-west part of Oregon. I've added county names to map but some text aren't well placed. I should probably use centroid, but then I'll have to import a shapefile to do this. I'll fix this later; I plan to add in fire locations.

### Time-series of geo-weighted regression estimates of smoke PM~2.5~ by county

Using the geofacet package to organize small-multiples by geography. 

*Note 11/7/17: Not sure how much I love the layout of this Oregon geofacet grid, but we'll see what people think. I like that geofacet lets you look at the two maps together to understand the exposure pattern, but too much whitespace. However, with this orientation, I believe you could cut out the smoke days figure.*

```{r geofacet time series of pm}
# use or_counties_grid from geo_facet 
or_grid <- geofacet::or_counties_grid1
# small multiples plot
plot <- ggplot(county_pm_df, aes(x=date, y= geo_smk_pm)) + 
  geom_point(color = "#00A08A", size = 0.5) +
  scale_x_date(date_labels = "%m") +
  geofacet::facet_geo(~county, grid = or_grid) +
  ylab(expression("Smoke PM2.5 µg/m"^3)) +
  xlab("Month in 2013") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    strip.text = element_text(size = 8),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(colour=NA, fill=NA),
    legend.position = "bottom")
# plot 
plot  
```

Elevated levels of smoke in late July to early August in Curry, Josephine, Jackson, and Klamath counties.

##3. Descriptive table of number of health outcomes

Importing casecross over dataframes.
**Note to Jingyang 11/3/17: Same issue as above. How many of these files needs to be uploaded to produce results? A lot of this seems redundant or inefficient. I cannot find a lot of outcome files I need. I also need the SABA casecrossover dataframe. Listing example of two casecross over dataframes for now. Let's talk about this.**

*Note 2017-11-14: It may be easiest to make a set of casecross over functions and put them in a package rather than import the timestratified casecross overs each time.*

```{r health data import, message=F, warning=F}
# path for health dataframe
health_path <- "../../data/health/"
# importing time-stratified case-crossover dataframe
casecross_files <- list.files(path=health_path, pattern="*casecross*")

# reorder file names in way I'd like it to be analyzed
# also ditching broken arm
casecross_order <- casecross_files[c(13,12,3,6,11,1,7,2,5,8,9,10)]

# extract the name of the dataframe after study type
file_names <- stringr::str_extract(casecross_order, 
  pattern="(?<=casecross_)\\w+")

# read in all the files in to a list
outcome_df_list <- casecross_order %>%  
  purrr::map(~read_csv(paste0(health_path, .)))

# name dataframes
names(outcome_df_list) <- file_names

# name list elements in order I'd like to present in document
outcome_names <- c("SABA", "Respiratory", "Asthma", "COPD", "Pneumonia", 
  "Acute Bronchitis", "Cardiovascular Disease", "Arrhythmia", 
  "Cerebrovascular Disease", "Heart Failure", "Ischemic Heart Disease", 
  "Myocardial Infarction")
```

CVD warning message on import. Have Jingyang check. Maybe why proportion of CVD vs respiratory so different in Oregon?
*Warning message:In rbind(names(probs), probs_f) :number of columns of result is not a multiple of vector length (arg 1)*

*Also warnings on mixed data types of NULL and numeric; another reason to revise and create timestratified casecross over functions*.

Descriptive table will go here. Jingyang, I'll have you add the other dataframes to analyze. I provided an example of Asthma and CVD. 

```{r descriptive table}
# creating a row calculation function
table1_fun <- function(data_list){
  # output of total n
  total_n <- data_list %>% 
    filter(outcome == 1) %>%
    # adding in a filter to remove NAs
    filter(!is.na(geo_smk_pm_zip)) %>% 
    summarise(total_n = n()) 

  # output row of summary numbers
  age_cat_n <- data_list %>% 
    filter(outcome == 1) %>%
    group_by(age_ind) %>% 
    summarise(n = n()) %>%
    # this will fix the 0 categories of certain CVD outcomes in children
    add_row(age_ind = 0, n = 0) %>% 
    arrange(age_ind) %>% 
    group_by(age_ind) %>% 
    summarise(n = sum(n)) %>% 
    mutate(age_cat = ifelse(age_ind == 0, "age_under15",
                    ifelse(age_ind == 1, "age_15to65", "age_over65")),
           # preserve factor order
           age_cat = parse_factor(age_cat, levels = age_cat)) %>% 
    select(-age_ind) %>% 
    spread(age_cat, n)
  # sex n
  sex_n <- data_list %>% 
    filter(outcome == 1) %>% 
    group_by(gender) %>% 
    summarise(n = n()) %>% 
    filter(gender != "U") %>% 
    spread(gender, n)
  # bind all rows together
  outcome_n_row <- bind_cols(total_n, age_cat_n, sex_n) %>% 
    mutate(perc_15 = round(age_under15/total_n,2), 
      perc_15to65 = round(age_15to65/total_n,2),
      perc_65 = round(age_over65/total_n,2),
      perc_F = round(F/total_n,2),
      perc_M = round(M/total_n,2)) %>% 
    select(total_n, age_under15, perc_15, age_15to65, perc_15to65, 
           age_over65, perc_65, F, perc_F, M, perc_M)
return(outcome_n_row)
} # end function
```

Table 1.

```{r descritive table}
# outcome names
outcome <- outcome_names %>%
  as_tibble() %>%
  rename(outcome = value)

# apply custom function to generate descriptive table
table_vals <- outcome_df_list %>%
  # map to dataframe
  map_dfr(~table1_fun(.))

# descriptive table, bind outcome names and values
descriptive_table <- bind_cols(outcome, table_vals)

# output table
knitr::kable(descriptive_table,
  caption = "Descriptive charactersitics of ED/urgent care visits")
```

##4. Same-day association results

*Note from Jingyang on Nov 14:*
*Just a little improvement advice for plot: Because the number (which labels the last disease's odds ratio) can only be seen one digital, I suggest to add more margin to the right side. Also for the DLM graph.*

*Note to Jingyang on Nov 16:*
*I still don't understand why the case n would be different from table 1 to the number of cases used in the models below? You should have identified all the cases in the time period of May to October, and then assigned them an exposure value. Referent values will be assigned at any other time point during that time as well. There should be no missing data in outcomes or exposure. You will have to tell me why cases are being included in the time-stratified dataframes, but excluded in analysis.*

Create function to calculate same-day association (odds ratio) and 95% confidence interval between increasing smoke and outcomes.

```{r same day association fuction}
same_day_fun <- function(data){
  # limit to complete cases
  complete_data <- data %>% 
    # filter to complete case for smoke
    filter(!is.na(geo_smk_pm_zip)) %>% 
    # create 10 unit smk variable 
    mutate(geo_smk10 = geo_smk_pm_zip/10)

    # fit conditional logistic regression model ----
  mod <- clogit(outcome ~ geo_smk10 + wrf_temp_zip + strata(personkey),
    data = complete_data)

  # odds ratio
  estimates <- round(exp(summary(mod)$coefficient[1,1]), 3) 
  # 95% lower bound
  lower95 <- round(exp((summary(mod)$coefficient[1,1]) -
                                    1.96*(summary(mod)$coefficient[1,3])), 3)
  # 95% upper bound
  upper95 <- round(exp((summary(mod)$coefficient[1,1]) +
                                    1.96*(summary(mod)$coefficient[1,3])), 3)
  
  return_estimate <- data_frame(estimates, lower95, upper95) 
  return(return_estimate) 
} 
```

Apply same-day function to each outcome dataframe.

```{r same day association table}
sameday_results <- outcome_df_list %>% 
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  select(outcome_names, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

knitr::kable(sameday_results, 
  caption = "Same day odds ratio and 95% CI of pharmacy/ED/urgent care visits")
```

Applying function to the list of outcome dataframes.

```{r same day association graph}
# ggplot ----
plot <- ggplot(sameday_results, aes(x=outcome_names, y = estimates)) +
  geom_point(colour = "#46ACC8") +
  geom_text(aes(label = round(estimates,2)), hjust = -0.25) +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                colour= "#46ACC8", width = 0.2) +
  geom_hline(yintercept = 1, linetype = 2, colour = "#B40F20") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
   panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(),
   axis.text.x = element_text(angle=90, hjust = 1)) +
  ylab(expression("Same day odds ratio: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Outcomes")

plot
```

##5. Distributed lag cumulative effect results

For this project, we use the time-stratified case-crossover study design in the same way we did for the 2012 Wenatchee-Complex fire project. Briefly, we identify admissions dates for ED or urgent care visits, and pharmacy fill dates for SABA, using billing records. 

In the Wenatchee-Complex fire project, we looked at the same-day relationship between smoke exposure and health outcomes. For the Douglas-complex fire, we will evaluate a 0 to 7 day distributed lag association, first comparing the overall cumulative effect over these 7 days, and then get in to the lagged effects.

*Note: 11/7/17: Jingyang will provide a csv of the best-fit knots for the distributed lag splines based on AIC.*

*Note: 11/7/17: Jingyang, can I use the lagged days in the case-crossover dataframes? Please confrim that the value for lag day 1 is the day before, lag day 2 is from 2 days before, etc..., and not the week before, two weeks before, etc... What does the _m denoter mean too? Jingyang says it's not necissary; we will remove creating this variable in the data management scripts. Do we use the patid or personkey identifier for strata? check.*

Basis function also included for WRF temp. We will need to find the best fit of spline for temp seperately from PM. For asthma, it looks like 2 DF is best.

Making a custom distributed lag function. Consider adding additional options like specifying number of lag days. That would require a reworking of how the case-crossovers are set up (kind of).

```{r distributed lag function}
# custom distributed lag function 
distributed_lag <- function(data, pm_df, temp_df, cumulative=T){
  # limit to complete cases
  complete_data <- data %>% 
    # filter to complete case for smoke
    filter(!is.na(geo_smk_pm_lag7_zip))

  # output matrix of gwr values
  pm_matrix <- complete_data %>% 
    select(contains("geo_smk_pm")) %>%
    # remove anything with m in it; will go back in original code and not create 
    # this to begin with
    select(-contains("_m")) %>% 
    # divide exposure values by 10 units to interpret on 10 ug/m^3 scale
    mutate_all(funs(./10)) %>% 
    # convert to matrix
    as.matrix()
  
  # output temp matrix
  temp_matrix <- complete_data %>% 
    select(contains("wrf_temp")) %>%
    # remove anything with m in it; will go back in original code and not create 
    # this to begin with
    select(-contains("_m")) %>% 
    # convert to matrix
    as.matrix()

  # calculation of basis ----
  # define basis using natural spline function from "splines"" package
  pm_b <- splines::ns(0:7, df=pm_df, intercept=T)
  # create pm basis
  pm_basis <- pm_matrix %*% pm_b
  # create temp basis
  temp_b <- splines::ns(0:7, df=temp_df, intercept=T)
  temp_basis <- temp_matrix %*% temp_b
  
  # fit model with basis ----
  mod <- clogit(outcome ~ pm_basis + temp_basis + strata(personkey),
    data = complete_data)
  
  # calculate estimates ----
  # output pm basis parameters
  dl_parms <- broom::tidy(mod) %>% 
    filter(stringr::str_detect(term, "pm")) %>% 
    select(estimate) %>% 
    as_vector()
  # estimate distributed lag values for each day
  dl_estimates <- data.frame(estimate = pm_b %*% dl_parms)
  # covariance matrix for knots
  cov_matrix <- as.matrix(vcov(mod))[1:3,1:3]
  
  # estimate variance of spline
  dl_var <- pm_b %*% cov_matrix %*% t(pm_b)
  # estimate standard error
  dl_estimates$stderr <- sqrt(diag(dl_var))
  
  # calculate lower and upper bound
  dl_estimates$lower95 <- dl_estimates$estimate-(dl_estimates$stderr*1.96)
  dl_estimates$upper95 <- dl_estimates$estimate+(dl_estimates$stderr*1.96)

    if(cumulative==T) {
      type <- "cumulative"  
      # cumulative outcome and 95CI
      estimate <- sum(dl_estimates$estimate)
      # stderr cumulative effect
      estimate_se <- sqrt(sum(dl_var))
      # cumulative 95CI
      lower95 <- estimate-(estimate_se*1.96)
      upper95 <- estimate+(estimate_se*1.96)
      # return dataframe
      return_estimate <- data_frame(type, estimate, lower95, upper95) %>% 
        mutate_if(is.numeric, exp)
      return(return_estimate)
    }
    else { # if cumulative is not true, or false, return distributed lag est
      # return dataframe
      return_estimate <- dl_estimates %>% 
        mutate_if(is.numeric, exp) %>% 
        mutate(type = "lag", 
               time = (as.numeric(rownames(.))-1)/-1) %>% 
        select(type, time, estimate, lower95, upper95)
       # return estimate  
      return(return_estimate)
      }
      # end of if
} 
```

Using the custom function to estimate cumulative effects for the list of dataframes. It will work on an individual dataframe, but I built it to use with the purrr map functions. 

*Note for Jingyang 11/8/17: purrr map functions are the tidyverse equivalents of apply-type functions*

```{r cumulative association}
# use custom function to create a dataframe of cumulative values
# using purrr::map_dfr function
# purrr::map_dfr will work if it's just the cumulative, but won't work for lagged
cumulative_results <- outcome_df_list %>% 
  map_dfr(~distributed_lag(., pm_df=3, temp_df=2, cumulative=T)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  select(outcome_names, type, estimate, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# will put this table eventually and split out plot
#head(cumulative_results)

# ggplot ----
plot <- ggplot(cumulative_results, aes(x=outcome_names, y = estimate)) +
  geom_point(colour = "#00A08A") +
  geom_text(aes(label = round(estimate,2)), hjust = -0.25) +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                colour= "#00A08A", width = 0.2) +
  geom_hline(yintercept = 1, linetype = 2, colour = "#FF0000") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
   panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(),
   axis.text.x = element_text(angle=90, hjust = 1)) +
  ylab(expression("Cumulative odds ratio: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Outcomes")

plot
```

This is generally how I'd like the plots to look, but I plan to add color grouping to SABA, respiratory, and CVD groupings. Also considering reducing the lag time evaluated since I think we are getting in to variance issues a week out with this dataset (as evidence, large error around asthma outcome relative to other studies).

I will also come back and tweak color scheme and labels.

##6. Distributed lag results

That same function can be used to generate detailed estimates of the association over time. In this case, we'll look at the same day to seven days prior the event.

```{r distributed lag}
# this approach will work that creates a list of dataframes with map then
# binds the lists together in one dataframe
dl_results <- outcome_df_list %>% 
  purrr::map(~distributed_lag(., pm_df=3,temp_df=2,cumulative=F)) %>% 
  plyr::rbind.fill() %>% 
  bind_cols(., data_frame(rep(outcome_names, each=8))) %>% 
  rename(outcome_names = `rep(outcome_names, each = 8)`) %>% 
  select(outcome_names, type, time, estimate, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# results will come in a format to make small multiples I think
#head(dl_results)

# small multiples DL plot ----
dl_plot <- ggplot(dl_results, aes(x=time, y=estimate)) +
  geom_line(colour = "#046C9A", size = 1) +
  geom_ribbon(aes(ymin = lower95, ymax = upper95), 
              fill = "#ABDDDE", alpha = 0.5) + 
  scale_y_continuous(limits = c(0.8, 1.2)) +
  scale_x_continuous(breaks = c(seq(-7, 0, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~outcome_names) +
  ylab(expression("Odd ratio for a 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Lagged Days") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    strip.text = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(colour=NA, fill=NA))

dl_plot
```

DL plot shows an effect with asthma even though the cumulative effect size is similar in magnitude to what we've seen before, but the 95% CIs overlap 1. I think this is a power issue trying to look at lagged effects for more than a week. I've applied a general 3 degrees of freedom knot for PM~2.5~ and 2 degrees of freedom knot for temperature. I think temperature is okay to do this, but I'm still figuring out a way to build a best-fit knot in to the function.

Worth discussing with the group.

##7. Stratified same-day results

*Note to Jingyang: Nov 16*
*I realized there is a better way to calculate stratified results than modifying the code. See below for example. There is a way to do it in one chunk rather than 2, but I was running in to errors.*

### 7.a Sex

Presenting same-day stratified results because the computations are easier. I'll use it to decide if we should present cumulative effects. We can use map and filter to subset to group of interest and apply our same-day function. We then bind the two strata together. 

```{r same day association stratified by sex}
# there is probably a better way to do this, but this will work.
sameday_results_f <- outcome_df_list %>% 
  # using gender because I forget which sex_ind is which
  # filter to females
  purrr::map(~filter(., gender == "F")) %>%  
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  mutate(sex = as.factor("Female")) %>% 
  select(outcome_names, sex, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

sameday_results_m <- outcome_df_list %>% 
  # filter to males
  purrr::map(~filter(., gender == "M")) %>%  
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  mutate(sex = as.factor("Male")) %>% 
  select(outcome_names, sex, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# bind sex dataframes together
sameday_results <- rbind(sameday_results_f, sameday_results_m)

# print table
knitr::kable(sameday_results, 
  caption = "Same day odds ratio and 95% CI of pharmacy/ED/urgent care visits stratified by sex.")
```

Plot.
```{r sex strata plot}
plot <- ggplot(data=sameday_results, aes(x=sex, y = estimates, color=sex)) +
  scale_color_manual(name = "Sex", values = c("#00A08A", "#046C9A"),
    guide = guide_legend(direction="horizontal", title.position = "top",
                         title.hjust = 0.5)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.2) +
  facet_wrap(~outcome_names) +
  geom_hline(yintercept = 1, linetype = 2, colour = "#FF0000") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom",
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black")) +
  ylab(expression("Odds ratio: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Sex")

plot  
```

### 7.b Age

Stratified by age category.

```{r same day association stratified by age category}
# subset outcomes evaluated for under 15
under15_outcome <- outcome_names[1:7]

# subset dataframes that won't have convergence issues
sameday_results_under15 <- outcome_df_list[1:7] %>% 
  # filter to children
  purrr::map(~filter(., age_ind == 0)) %>%  
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(under15_outcome)) %>% 
  rename(outcome_names = under15_outcome) %>% 
  mutate(age_cat = as.factor("Under 15")) %>% 
  select(outcome_names, age_cat, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# age category 1
sameday_results_15to65 <- outcome_df_list %>% 
  # filter to males
  purrr::map(~filter(., age_ind == "1")) %>%  
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  mutate(age_cat = as.factor("15 to 65")) %>% 
  select(outcome_names, age_cat, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# age category 2
sameday_results_over65 <- outcome_df_list %>% 
  purrr::map(~filter(., age_ind == "2")) %>%  
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., data_frame(outcome_names)) %>% 
  mutate(age_cat = as.factor("Over 65")) %>% 
  select(outcome_names, age_cat, estimates, lower95, upper95) %>% 
  # preserve order of names
  mutate(outcome_names = parse_factor(outcome_names, levels = outcome_names))

# bind sex dataframes together
sameday_results <- rbind(sameday_results_under15, sameday_results_15to65,
                         sameday_results_over65)

# print table
knitr::kable(sameday_results, 
  caption = "Same day odds ratio and 95% CI of pharmacy/ED/urgent care visits stratified by age category.")
```

Stratified by age plot.
```{r age strata plot}
plot <- ggplot(data=sameday_results, 
               aes(x=age_cat, y = estimates, color=age_cat)) +
  scale_color_manual(name = "Age Category", 
    values = c("#899DA4", "#35274A", "#F2300F"),
    guide = guide_legend(direction="horizontal", title.position = "top",
                         title.hjust = 0.5)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.2) +
  facet_wrap(~outcome_names, scales = "free_y") +
  geom_hline(yintercept = 1, linetype = 2, colour = "#FF0000") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom",
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black")) +
  ylab(expression("Odds ratio: 10 ug/m^3 increase smoke PM"[2.5])) +
  xlab("Age Category")

plot  
```

Under 15 unstable for CVD; consider removing. Heart failure is interesting for the over 65 group. That may agree with what Anna Rappold has seen.

##8. SABA same-day results by underlying respiratory diagnosis

```{r saba underlying dx}
# read in the index 
saba_index <- read_csv("../../data/health/oregon_saba_index.csv") %>% 
    mutate(underlying_dx = as.factor(ifelse(index == "copd",
    stringr::str_to_upper(index),
    stringr::str_to_title(index)))) %>% 
    select(-index)

# index vector
underlying_dx <- unique(as.factor(saba_index$underlying_dx)) %>% 
  data_frame() %>% 
  rename(underlying_dx = ".") %>% 
  mutate(underlying_dx = ) %>% 
  # need to arrange since slice is going alphabetical
  arrange(underlying_dx)

# join index to saba
# extract saba dataframe from list
saba <- outcome_df_list[[1]] %>% 
  left_join(saba_index, by = "personkey")

# run function on each group
sameday_results <- saba %>% 
  split(.$underlying_dx) %>% 
  map_dfr(~same_day_fun(.)) %>% 
  bind_cols(., underlying_dx) %>% 
  select(4,1:3)

# table
knitr::kable(sameday_results, 
  caption = "Same day odds ratio and 95% CI for a SABA fill, stratified by underlying dx.")
```

*Jingyang, did I ask you to code "other" if a dx was missing? Maybe we should change other to "unknown or other" since I doubt we were able to link an underlying dx to everyone with a fill.*

Plot of SABA underlying Dx categories.

```{r plot saba underlying dx}
plot <- ggplot(sameday_results, 
   aes(x=underlying_dx, y = estimates, color = underlying_dx)) +
   scale_color_manual(name = "Underlying Diagnosis", 
    values = c("#0B775E","#46ACC8","#E58601","#B40F20"),
    guide = guide_legend(direction="horizontal", title.position = "top",
                         title.hjust = 0.5)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower95, ymax=upper95), width = 0.2) +
  geom_hline(yintercept = 1, linetype = 2, colour = "#FF0000") +
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
   panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(),
   axis.title.x = element_blank(),
   legend.position = "bottom") +
  ylab(expression("Odds Ratio: 10 ug/m^3 increase smoke PM"[2.5])) 
# plot
plot
```

##9. Stratified cumulative results
Considering adding.

##10. SABA cumulative effect by underlying respiratory diagnosis
Considering adding.

##11. Conculsions
So far, it looks like SABA and Asthma are the only associtions. Furthermore, the cumulative 0-7 day relationship between asthma and smoke has wide error bars and overlaps 1, suggesting the association could be null. I think it's more likely that this is because we introduce some noise on lag days 4-7. It's possible that an adjustment like weekend may help. It may also make sense to do something similar to Anna Rappold or others and shorten our lagged response. I also think this is a produce of sample size too. 

### Issues/Concerns (in order of time they popped in my head):
1. File structure needs to be cleaned up. There are way too many subdirectories.
2. Remove r code files that are not useful. There are too many files with similar code inside.
3. Variables in the casecross over datasets raise some questions.
4. Consider a cumulative effect that adds the preceding day and so on, i.e. 0, 0+1, 0+1+2, ...
5. Plots need to have standard labels, ordering, scales, etc.


